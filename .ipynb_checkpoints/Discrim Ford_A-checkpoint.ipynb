{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from ignite.handlers.param_scheduler import create_lr_scheduler_with_warmup\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "\n",
    "from typing import Dict, Any, Tuple, List, Union, Sequence, Callable\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "from utils.attacks import IterGradAttack, fgsm_attack, fgsm_reg_attack\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1,  1]), array([1846, 1755]))\n",
      "(array([-1,  1]), array([681, 639]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3601, 500), (1320, 500), (3601,), (1320,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'FordA'\n",
    "\n",
    "import sktime\n",
    "from sktime.datasets import load_from_tsfile\n",
    "\n",
    "x_train, y_train = load_from_tsfile(\"data/Ford_A/FordA_TRAIN.ts\")\n",
    "x_test, y_test = load_from_tsfile(\"data/Ford_A/FordA_TEST.ts\")\n",
    "\n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_X(X):\n",
    "    np_data = []\n",
    "    lens = []\n",
    "    for i in range(len(X)):\n",
    "        line = X.iloc[i, 0]\n",
    "        lens.append(len(line))\n",
    "        np_data.append(line)\n",
    "        \n",
    "    #print(np.mean(lens), np.std(lens))\n",
    "    return np.array(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36010, 50) (13200, 50) (36010, 1) (13200, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f55e2986610>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window = 50\n",
    "len_seq = x_train.shape[1]\n",
    "n_patches = len_seq//window\n",
    "\n",
    "X_train = np.vstack([x_train[:, i:i+window] for i in range(n_patches)])\n",
    "X_test = np.vstack([x_test[:, i:i+window] for i in range(n_patches)])\n",
    "\n",
    "y_train = np.array([(int(y)+1) // 2 for y in y_train])\n",
    "y_test = np.array([(int(y)+1) // 2 for y in y_test])\n",
    "\n",
    "y_train = np.vstack([y_train.reshape(-1, 1) for i in range(n_patches)])\n",
    "y_test = np.vstack([y_test.reshape(-1, 1) for i in range(n_patches)])\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "plt.plot(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor =torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, window=50):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.window=window\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        \n",
    "#         start_ind = np.random.randint(0, len(X) - self.window)\n",
    "#         X = X[start_ind:start_ind+self.window]\n",
    "        X = X.reshape([-1, 1])\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "BS = 64    \n",
    "train_loader = DataLoader(MyDataset(X_train[50:], y_train[50:]), batch_size=BS, shuffle=True)\n",
    "test_loader = DataLoader(MyDataset(X_test[50:], y_test[50:]), batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_layers, output_dim=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(1, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(data)\n",
    "        hidden = hidden.reshape(hidden.shape[1], hidden.shape[2])\n",
    "        \n",
    "        hidden = self.dropout(hidden)\n",
    "        output = self.relu(self.fc1(hidden))\n",
    "        output = self.fc2(self.dropout(output))\n",
    "        output = torch.sigmoid(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, loader, criterion, device, optimizer, scheduler=None):\n",
    "    losses, n_batches = 0, 0\n",
    "    model.train(True)\n",
    "    for x, labels in loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        labels = labels.reshape(-1, 1).to(device)\n",
    "        \n",
    "        y_out = model(x)\n",
    "        loss = criterion(y_out, labels) \n",
    "        \n",
    "        loss.backward()     \n",
    "        optimizer.step()\n",
    "        losses += loss\n",
    "        n_batches += 1\n",
    "\n",
    "    mean_loss = losses / n_batches\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    return mean_loss\n",
    "\n",
    "def valid_step(model, loader, criterion, device):\n",
    "    \n",
    "    losses, n_batches = 0, 0\n",
    "    model.eval()    \n",
    "    for x, labels in loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            labels = labels.reshape(-1, 1).to(device)\n",
    "\n",
    "            y_out = model(x)\n",
    "            loss = criterion(y_out, labels)\n",
    "            losses += loss\n",
    "\n",
    "            n_batches += 1\n",
    "\n",
    "    mean_loss = losses / n_batches\n",
    "    return mean_loss\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pr = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return acc, pr, rec, f1\n",
    "    \n",
    "def estimate_epoch(loader, model=None, device='cpu', round_=True, multiclass=False):\n",
    "    \n",
    "    y_all_pred = torch.tensor([])\n",
    "    y_all_true = torch.tensor([])\n",
    "    \n",
    "    for X, y_true in loader:\n",
    "        X = X.to(device)\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        if multiclass:\n",
    "            y_pred = torch.argmax(y_pred, axis=1)\n",
    "        else:\n",
    "            y_pred = torch.round(y_pred)\n",
    "        \n",
    "        y_all_true = torch.cat((y_all_true, y_true.cpu().detach()), dim=0)\n",
    "        y_all_pred = torch.cat((y_all_pred, y_pred.cpu().detach()), dim=0)\n",
    "        \n",
    "    y_all_pred = y_all_pred.numpy().reshape([-1, 1])\n",
    "    y_all_true = y_all_true.numpy().reshape([-1, 1])\n",
    "    \n",
    "    acc, pr, rec, f1 = calculate_metrics(y_all_true, y_all_pred)\n",
    "    \n",
    "    return acc, pr, rec, f1\n",
    "\n",
    "def train_procedure(model, train_loader, test_loader, criterion, optimizer, scheduler=None,\n",
    "                   num_epochs=30, step_print=5):\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss = train_step(model, train_loader, criterion, device, optimizer, scheduler)\n",
    "        test_loss = valid_step(model, test_loader, criterion, device) \n",
    "\n",
    "        acc_train, pr_train, rec_train, f1_train = estimate_epoch(train_loader, model, device=device)\n",
    "        acc_test, pr_test, rec_test, f1_test = estimate_epoch(test_loader, model, device=device)\n",
    "\n",
    "        if epoch % step_print == 0:\n",
    "            print(f'[Epoch {epoch + 1}] train loss: {train_loss:.3f}; acc_train {acc_train:.3f}; f1_train {f1_train:.3f}; test loss: {test_loss:.3f}; acc_test {acc_test:.3f}; f1_test {f1_test:.3f};')\n",
    "#             plt.hist(y_test_pred)\n",
    "#             plt.show()\n",
    "            \n",
    "    return model\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pr = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return acc, pr, rec, f1\n",
    "\n",
    "def plotting(y_true, y_pred, window=1000):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(y_true[-window:], label = 'True')\n",
    "    plt.plot(y_pred[-window:], label = 'Pred')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor =torch.tensor(X_test, dtype=torch.float32)\n",
    "X_train_tensor = X_train_tensor.reshape([X_train_tensor.shape[0],X_train_tensor.shape[1], 1])\n",
    "X_test_tensor = X_test_tensor.reshape([X_test_tensor.shape[0],X_test_tensor.shape[1], 1])\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "# #device = 'cpu'\n",
    "\n",
    "# num_epochs = 15\n",
    "# #print(num_epochs)\n",
    "# LR = 0.001\n",
    "\n",
    "# HIDDEN_DIM = 50\n",
    "# OUTPUT_DIM = 1\n",
    "# N_LAYERS = 1\n",
    "# DROPOUT = 0.3\n",
    "\n",
    "# for model_id in range(5):\n",
    "#     print(model_id)\n",
    "#     torch.manual_seed(model_id)\n",
    "\n",
    "#     model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "\n",
    "#     criterion = torch.nn.BCELoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 12, gamma=0.1)\n",
    "    \n",
    "#     model = train_procedure(model, train_loader, test_loader, criterion, optimizer,\n",
    "#                 num_epochs=15, step_print=5)\n",
    "    \n",
    "#     torch.save(model.state_dict(), f'checkpoints/Ford_A/model_{model_id}_{col}.pth') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting adv Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(loss_val, x, eps):\n",
    "    \n",
    "    grad_ = torch.autograd.grad(loss_val, x, retain_graph=True)[0]\n",
    "    x_adv = x.data + eps * torch.sign(grad_)\n",
    "    return x_adv\n",
    "    \n",
    "def fgsm_reg_attack(loss_val, x, eps, alpha):\n",
    "    \n",
    "    x_anchor = x[:, 1:-1]\n",
    "    x_left = x[:, 2:]\n",
    "    x_right = x[:, :-2]\n",
    "    x_regular = (x_left + x_right) / 2\n",
    "    loss_reg = torch.sum((x_anchor - x_regular.detach()) ** 2, dim=list(range(1, len(x.shape))))\n",
    "    \n",
    "    loss = loss_val - alpha * torch.mean(loss_reg)\n",
    "    grad_ = torch.autograd.grad(loss, x, retain_graph=True)[0]\n",
    "    x_adv = x.data + eps * (torch.sign(grad_))\n",
    "\n",
    "    return x_adv\n",
    "\n",
    "\n",
    "def attack_one_iter(\n",
    "        model: nn.Module,  # model for attack\n",
    "        loader: DataLoader,  # dataloader with data\n",
    "        criterion: nn.Module,\n",
    "        attack_fun,\n",
    "        attack_params,\n",
    "        device='cpu',\n",
    "        train_mode=False):  # params_dict with eps and iter number\n",
    "\n",
    "    \"\"\"\n",
    "    Applies 1 iteration of ifgsm adversarial attack to data\n",
    "    :param model: model to get grad\n",
    "    :param loader: dataloader with data\n",
    "    :param criterion: loss function to calculate gradient for attack\n",
    "    :param eps: the strengh of attack\n",
    "    :param train_mode: bool to change mode of the model: should be False,\n",
    "                       but RNN layers can't calculate grad with False value, so need to be set as True\n",
    "    :return: x_adv_tensor - adversarial data,\n",
    "            all_y_true - true labels,\n",
    "            all_preds - predinctions before attack,\n",
    "            all_preds_adv - predinctions on attacked data\n",
    "    \"\"\"\n",
    "    model.train(train_mode)\n",
    "    req_grad(model, state=False)  # detach all model's parameters\n",
    "\n",
    "    all_y_true = []  # logging y_true for rebuilding dataloader and calculation difference with preds\n",
    "    all_preds = []  # logging predictions original for calculation difference with data\n",
    "    all_preds_adv = []  # logging predictions for calculation difference with data\n",
    "    x_adv_tensor = torch.FloatTensor([])  # logging x_adv for rebuilding dataloader\n",
    "\n",
    "    for x, y_true in loader:\n",
    "        all_y_true.extend(y_true.detach().data.numpy())\n",
    "\n",
    "        x.grad = None\n",
    "        x.requires_grad = True\n",
    "\n",
    "        # prediction for original input\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "\n",
    "        # attack for adv input\n",
    "        loss_val = criterion(y_pred, y_true.reshape(-1, 1))\n",
    "        x_adv = attack_fun(loss_val, x, **attack_params)\n",
    "        x_adv_tensor = torch.cat((x_adv_tensor, x_adv.cpu().detach()), dim=0)\n",
    "\n",
    "        # assert (x_adv == x).sum() == 0, \"Data doesn't change after attack\"\n",
    "        all_preds.extend(y_pred.cpu().detach().data.numpy())\n",
    "\n",
    "        # prediction for adv input\n",
    "        with torch.no_grad():\n",
    "            y_pred_adv = model(x_adv)\n",
    "            all_preds_adv.extend(y_pred_adv.cpu().detach().data.numpy())\n",
    "\n",
    "        # assert (y_pred_adv == y_pred).sum() == 0, \"Predicitions doesn't change after attack\"\n",
    "\n",
    "    return x_adv_tensor, all_y_true, all_preds, all_preds_adv\n",
    "\n",
    "\n",
    "def attack_iterations_data(model: nn.Module,\n",
    "                     loader: DataLoader,\n",
    "                     dataset_class: Dataset,\n",
    "                     criterion: nn.Module,\n",
    "                     attack_fun,\n",
    "                     attack_params,\n",
    "                     n_steps: int,\n",
    "                     device='cpu',\n",
    "                     train_mode=False,\n",
    "                     ):\n",
    "\n",
    "    for iter_ in tqdm(range(n_steps)):\n",
    "\n",
    "        # attack\n",
    "        x_adv_tensor, y_true, preds_original, preds_adv = attack_one_iter(model=model, \n",
    "                                                                          loader=loader, \n",
    "                                                                          criterion=criterion, \n",
    "                                                                          attack_fun=attack_fun,\n",
    "                                                                          attack_params=attack_params, \n",
    "                                                                          device=device, \n",
    "                                                                          train_mode=train_mode)\n",
    "\n",
    "        # rebuilding dataloader for new iteration\n",
    "        it_dataset = dataset_class(x_adv_tensor, torch.tensor(y_true))\n",
    "        loader = DataLoader(it_dataset, batch_size=loader.batch_size)\n",
    "\n",
    "    return torch.tensor(x_adv_tensor).detach(), torch.tensor(y_true).detach()\n",
    "\n",
    "\n",
    "def req_grad(model: nn.Module, state: bool = True) -> None:\n",
    "    \"\"\"Set requires_grad of all model parameters to the desired value.\n",
    "\n",
    "    :param model: the model\n",
    "    :param state: desired value for requires_grad\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(state)\n",
    "\n",
    "def prepare_adv_data(\n",
    "        model: nn.Module,  # model for attack\n",
    "        loader: DataLoader,  # dataloader with data\n",
    "        criterion: nn.Module,\n",
    "        attack_func,\n",
    "        attack_params,\n",
    "        device='cpu',\n",
    "        train_mode=False):  # params_dict with eps and iter number\n",
    "\n",
    "    model.train(train_mode)\n",
    "    req_grad(model, state=False)  # detach all model's parameters\n",
    "\n",
    "    all_y_true = torch.tensor([]) # logging y_true for rebuilding dataloader and calculation difference with preds\n",
    "    x_adv_tensor = torch.FloatTensor([])  # logging x_adv for rebuilding dataloader\n",
    "\n",
    "    for x, y_true in loader:\n",
    "        \n",
    "        all_y_true = torch.cat((all_y_true, y_true.cpu().detach()), dim=0)\n",
    "        x.grad = None\n",
    "        x.requires_grad = True\n",
    "\n",
    "        # prediction for original input\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # attack for adv input\n",
    "        loss_val = criterion(y_pred, y_true.reshape(-1, 1))\n",
    "        x_adv = attack_fun(loss_val, x, **attack_params)\n",
    "        x_adv_tensor = torch.cat((x_adv_tensor, x_adv.cpu().detach()), dim=0)\n",
    "\n",
    "    return x_adv_tensor.detach(), all_y_true.detach()\n",
    "\n",
    "\n",
    "def prepare_disc_data(model, \n",
    "                      loader, \n",
    "                      dataset_class,\n",
    "                      X_tensor, \n",
    "                      criterion,\n",
    "                      attack_fun,\n",
    "                      attack_params, \n",
    "                      n_steps,\n",
    "                      device, \n",
    "                      batch_size,\n",
    "                      train_mode=True):\n",
    "    \n",
    "\n",
    "    X_adv, y_adv = attack_iterations_data(model, loader, dataset_class, criterion, attack_fun, attack_params,\n",
    "                                          n_steps, device, train_mode=train_mode)\n",
    "\n",
    "    \n",
    "    \n",
    "    disc_labels_zeros = torch.zeros((len(X_tensor), 1)) #True label class\n",
    "    disc_labels_ones = torch.ones(y_adv.shape) #True label class\n",
    "    \n",
    "    new_x = torch.concat([X_tensor, X_adv], dim=0)\n",
    "    new_y = torch.concat([disc_labels_zeros, disc_labels_ones], dim=0)\n",
    "    \n",
    "    disc_loader = DataLoader(dataset_class(new_x, new_y), batch_size=BS, shuffle=True)\n",
    "    \n",
    "    return disc_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HideAttackExp:\n",
    "    def __init__(self, attack_model, train_loader, test_loader, attack_train_params, \n",
    "                 attack_test_params, discriminator_model, disc_train_params, multiclass=False):\n",
    "        \n",
    "        self.attack_loaders = {'train': train_loader,\n",
    "                       'test': test_loader}\n",
    "        self.attack_train = {'train':IterGradAttack(attack_model, train_loader, **attack_train_params),\n",
    "                             'test': IterGradAttack(attack_model, test_loader, **attack_test_params)}\n",
    "        self.disc_loaders = dict()\n",
    "        \n",
    "        self.attack_train_params = attack_train_params\n",
    "        self.attack_test_params = attack_test_params\n",
    "        \n",
    "        \n",
    "        self.eps = attack_train_params['attack_params']['eps']\n",
    "        self.alpha = None\n",
    "        if 'alpha' in attack_train_params['attack_params']:\n",
    "            self.alpha = attack_train_params['attack_params']['alpha']\n",
    "        self.n_steps = attack_train_params['n_steps']\n",
    "        self.multiclass = multiclass\n",
    "\n",
    "        \n",
    "        self.attack_model = attack_model\n",
    "        self.disc_model = discriminator_model\n",
    "        \n",
    "        self.disc_criterion = torch.nn.BCELoss()\n",
    "        self.disc_n_epoch = disc_train_params['n_epoch']\n",
    "        self.disc_batch_size = 64\n",
    "        self.disc_optimizer = disc_train_params['optimizer']\n",
    "        if 'scheduler' in disc_train_params.keys():\n",
    "            self.disc_scheduler = disc_train_params['scheduler']\n",
    "        else:\n",
    "            self.disc_scheduler = None\n",
    "\n",
    "        self.attack_device = next(attack_model.parameters()).device\n",
    "        self.disc_device = next(discriminator_model.parameters()).device\n",
    "        \n",
    "    def run(self):\n",
    "        print(\"Generating adv data\")\n",
    "        self.get_disc_dataloaders()\n",
    "        print(\"Train discriminator\")\n",
    "        self.train_discriminator()\n",
    "    \n",
    "    def _generate_adv_data(self, mode='train', batch_size=64):\n",
    "        \n",
    "        self.disc_batch_size = batch_size\n",
    "        dataset_class = self.attack_train[mode].dataset_class\n",
    "\n",
    "        X_adv, y_adv = self.attack_train[mode].run_iterations()\n",
    "        X_orig = torch.tensor(self.attack_loaders[mode].dataset.X)\n",
    "        X_adv = X_adv.squeeze(-1)\n",
    "    \n",
    "        disc_labels_zeros = torch.zeros((len(X_orig), 1)) #True label class\n",
    "        disc_labels_ones = torch.ones(y_adv.shape) #True label class\n",
    "        \n",
    "        new_x = torch.concat([X_orig, X_adv], dim=0)\n",
    "        new_y = torch.concat([disc_labels_zeros, disc_labels_ones], dim=0)\n",
    "\n",
    "        suffle_status = mode == 'train'\n",
    "        disc_loader = DataLoader(dataset_class(new_x, new_y), batch_size=batch_size, shuffle=suffle_status)\n",
    "        self.disc_loaders[mode] = disc_loader\n",
    "        return disc_loader\n",
    "    \n",
    "    def get_disc_dataloaders(self):\n",
    "        self._generate_adv_data('train')\n",
    "        self._generate_adv_data('test')\n",
    "        \n",
    "    def _logging_train_disc(self, data, mode='train'):\n",
    "        \n",
    "        for metric in self.dict_logging[mode].keys():\n",
    "            self.dict_logging[mode][metric].append(data[metric])\n",
    "    \n",
    "    def train_discriminator(self):\n",
    "        metric_names = ['loss', 'accuracy', 'precision', 'recall', 'f1', 'balance']\n",
    "        self.dict_logging = {'train': {metric:[] for metric in metric_names},\n",
    "                       'test': {metric:[] for metric in metric_names}}\n",
    "\n",
    "        for epoch in tqdm(range(self.disc_n_epoch)):\n",
    "            train_metrics_epoch = self._train_step()\n",
    "            train_metrics_epoch = {met_name:met_val for met_name, met_val\n",
    "                                   in zip(metric_names, train_metrics_epoch)}\n",
    "            self._logging_train_disc(train_metrics_epoch, mode='train')\n",
    "            \n",
    "            test_metrics_epoch = self._valid_step() \n",
    "            test_metrics_epoch = {met_name:met_val for met_name, met_val \n",
    "                       in zip(metric_names, test_metrics_epoch)}\n",
    "            self._logging_train_disc(test_metrics_epoch, mode='test')\n",
    "                    \n",
    "    \n",
    "    def _train_step(self):\n",
    "        losses, n_batches = 0, 0\n",
    "        \n",
    "        y_all_pred = torch.tensor([])\n",
    "        y_all_true = torch.tensor([])\n",
    "        \n",
    "        self.disc_model.train(True)\n",
    "        for x, labels in self.disc_loaders['train']:\n",
    "\n",
    "            self.disc_optimizer.zero_grad()\n",
    "            x = x.to(self.disc_device)\n",
    "            labels = labels.reshape(-1, 1).to(self.disc_device)\n",
    "\n",
    "            y_out = self.disc_model(x)\n",
    "            \n",
    "            loss = self.disc_criterion(y_out, labels) \n",
    "\n",
    "            loss.backward()     \n",
    "            self.disc_optimizer.step()\n",
    "            losses += loss\n",
    "            n_batches += 1\n",
    "            \n",
    "            if self.multiclass:\n",
    "                y_pred = torch.argmax(y_out, axis=1)\n",
    "            else:\n",
    "                y_pred = torch.round(y_out)\n",
    "\n",
    "            y_all_true = torch.cat((y_all_true, labels.cpu().detach()), dim=0)\n",
    "            y_all_pred = torch.cat((y_all_pred, y_pred.cpu().detach()), dim=0)\n",
    "\n",
    "        mean_loss = losses / n_batches\n",
    "\n",
    "        if self.disc_scheduler:\n",
    "            self.disc_scheduler.step()\n",
    "            \n",
    "        y_all_pred = y_all_pred.numpy().reshape([-1, 1])\n",
    "        y_all_true = y_all_true.numpy().reshape([-1, 1])\n",
    "\n",
    "        acc, pr, rec, f1 = self.calculate_metrics(y_all_true, y_all_pred)\n",
    "        balance = np.sum(y_all_pred) / len(y_all_pred)\n",
    "        return mean_loss, acc, pr, rec, f1, balance\n",
    "\n",
    "\n",
    "    def _valid_step(self):\n",
    "        \n",
    "        y_all_pred = torch.tensor([])\n",
    "        y_all_true = torch.tensor([])\n",
    "        \n",
    "        losses, n_batches = 0, 0\n",
    "        self.disc_model.eval()    \n",
    "        for x, labels in self.disc_loaders['test']:\n",
    "            with torch.no_grad():\n",
    "                x = x.to(self.disc_device)\n",
    "                labels = labels.reshape(-1, 1).to(self.disc_device)\n",
    "\n",
    "                y_out = self.disc_model(x)\n",
    "                loss = self.disc_criterion(y_out, labels)\n",
    "                losses += loss\n",
    "                n_batches += 1\n",
    "                \n",
    "                if self.multiclass:\n",
    "                    y_pred = torch.argmax(y_out, axis=1)\n",
    "                else:\n",
    "                    y_pred = torch.round(y_out)\n",
    "\n",
    "            y_all_true = torch.cat((y_all_true, labels.cpu().detach()), dim=0)\n",
    "            y_all_pred = torch.cat((y_all_pred, y_pred.cpu().detach()), dim=0)\n",
    "\n",
    "        mean_loss = losses / n_batches\n",
    "        \n",
    "        y_all_pred = y_all_pred.numpy().reshape([-1, 1])\n",
    "        y_all_true = y_all_true.numpy().reshape([-1, 1])\n",
    "\n",
    "        acc, pr, rec, f1 = self.calculate_metrics(y_all_true, y_all_pred)\n",
    "        balance = np.sum(y_all_pred) / len(y_all_pred)\n",
    "        return mean_loss, acc, pr, rec, f1, balance\n",
    "\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        pr = precision_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        return acc, pr, rec, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attack model loading\n",
    "model_id = 0\n",
    "path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "\n",
    "device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "attack_model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "attack_model.load_state_dict(copy.deepcopy(torch.load(model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f84c50ce5b4500bc8398aae1d49547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3d037c1b3c4434a183d00d50ef6251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc62217347fb4d9b97330269a5068c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "LR = 0.001\n",
    "step_lr = 12\n",
    "\n",
    "\n",
    "attack_train_params = {'attack_func':fgsm_reg_attack, \n",
    "                      'attack_params':{'eps':0.03, 'alpha':0.01}, \n",
    "                      'criterion':torch.nn.BCELoss(), \n",
    "                      'n_steps':10,\n",
    "                      'train_mode': True}\n",
    "attack_test_params = attack_train_params\n",
    "\n",
    "\n",
    "discriminator_model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "optimizer = torch.optim.Adam(discriminator_model.parameters(), lr=LR)\n",
    "disc_train_params = {'n_epoch': 20,\n",
    "                    'optimizer': optimizer,\n",
    "                    'scheduler': torch.optim.lr_scheduler.StepLR(optimizer, step_lr, gamma=0.1)}      \n",
    "\n",
    "\n",
    "experiment = HideAttackExp(attack_model, train_loader, test_loader, attack_train_params, \n",
    "                           attack_test_params, discriminator_model, disc_train_params)\n",
    "experiment.run()\n",
    "\n",
    "with open(f'results/Ford_A/Gegular/Discriminator_pickle/fgsm_reg_eps={eps}_alpha={alpha}_nsteps={n_steps}.pickle', 'wb') as f:\n",
    "    pickle.dump(experiment, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_id_experiment(function, nn_params, eps=0.03, alpha=0.01, n_steps=10, model_id=0):\n",
    "    path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "    device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    attack_model = LSTM_net(*nn_params).to(device)\n",
    "    model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "    attack_model.load_state_dict(copy.deepcopy(torch.load(model_path)))\n",
    "    \n",
    "    if \"reg\" in function.__name__:\n",
    "        attack_param_eps_alpha = {'eps':eps, 'alpha':alpha}\n",
    "    else:\n",
    "        attack_param_eps_alpha = {'eps':eps}\n",
    "    attack_train_params = {'attack_func':function, \n",
    "                     'attack_params':attack_param_eps_alpha, \n",
    "                     'criterion':torch.nn.BCELoss(), \n",
    "                     'n_steps':n_steps,\n",
    "                      'train_mode': True}\n",
    "    attack_test_params = attack_train_params\n",
    "\n",
    "    LR = 0.001\n",
    "    step_lr = 12\n",
    "    discriminator_model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "    optimizer = torch.optim.Adam(discriminator_model.parameters(), lr=LR)\n",
    "    disc_train_params = {'n_epoch': 20,\n",
    "                        'optimizer': optimizer,\n",
    "                        'scheduler': torch.optim.lr_scheduler.StepLR(optimizer, step_lr, gamma=0.1)}      \n",
    "\n",
    "\n",
    "    experiment = HideAttackExp(attack_model, train_loader, test_loader, attack_train_params, \n",
    "                               attack_test_params, discriminator_model, disc_train_params)\n",
    "    experiment.run()\n",
    "    \n",
    "    if \"reg\" in function.__name__:\n",
    "        exp_name = f\"{function.__name__}_eps={eps}_alpha={alpha}_nsteps={n_steps}\"\n",
    "    else:\n",
    "        exp_name = f\"{function.__name__}_eps={eps}_nsteps={n_steps}\"\n",
    "    \n",
    "    exp_path = 'results/Ford_A/Gegular/Discriminator_pickle/'\n",
    "    \n",
    "    if exp_name not in os.listdir(exp_path):\n",
    "        os.mkdir(exp_path+exp_name+'/')\n",
    "        \n",
    "    with open(exp_path+exp_name+'/' + f\"{model_id}.pickle\", 'wb') as f:\n",
    "        pickle.dump(experiment, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_experiments = [{'function': fgsm_reg_attack, 'eps':0.3, 'alpha': 0.01, 'n_steps':1},\n",
    "#                    {'function': fgsm_reg_attack, 'eps':0.03, 'alpha': 0.01, 'n_steps':10},\n",
    "#                    {'function': fgsm_reg_attack, 'eps':0.03, 'alpha': 0.001, 'n_steps':10},\n",
    "#                     {'function': fgsm_reg_attack, 'eps':0.03, 'alpha': 0.001, 'n_steps':10},\n",
    "list_experiments = [{'function': fgsm_attack, 'eps':0.3, 'n_steps':1},\n",
    "                   {'function': fgsm_attack, 'eps':0.03, 'n_steps':10},\n",
    "                    {'function': fgsm_reg_attack, 'eps':0.03, 'n_steps':10},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffed93d8a3e498d83b1dac7cfb1b816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027c784f6698480cb74ac840f8e28cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0a0ac0b1264f79a68232fccacfc83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cc343ddc7b455b88de1566e5149bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055687d12d7b4d4687e7b348201d8131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dac9c67dac46b9a0e5d66918586163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cf099ac9564cbfaec48e756bc103ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93e80b5d74b4408874f8d682c4d7ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54375b93cd6d42f0b6fdcfdaad925b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8b6d0ce0cf4521a114130417304b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3427d2153deb465b995ba869b2e5152b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a758f08941734249a9fe127faceb6fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68f88363dec49cb86c2110a3ffe6edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5c7bacdc2f4473b538274dec4cd97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19f7a80736f41f387b35241424500ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0b79da196c422e8e120358fd2c4c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0f07f45b9246b6aef2dc279e9b1b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4709bac20da4650b4e0bb3a8664d269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d913ce1ac0834efda041e36c6c0d4864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cef2aec5aa3450dae79c35a983048b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd898ee1ed73471e81185488f7e00d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8ad66b6a8b4734876cff2d6a55be95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ddb9cf39994afe8a666c149b0538b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a364856aff854008aaae3b96308b46f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc41c2ccb8ed447f8ba427440dfe0afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71e650287be4bccbb28c94f36372d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffc83cc7d964d93a496fc3e92cd8934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6f3dd802704f70a9750733d2aa58b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cc90610fb94957adf9ae50a86214b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15e2e76785f4ae48249812e7a4ac6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d492ac2348ef480f978efa76db76ef49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0c4e515e8c4dffbacba0658cfa000b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd5471f5bdb40c2a9b2a8bbe7b4a123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6317fc283084c78a09df481357048dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e6648fc39849bdbba26979ef1a412b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c92cbf282c840f0a03579ceb07b013b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e90af4e76d4b318d61bf5ba43fcdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd4f926feca44378cdf3c1470485c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da871ab5c5a46ada4a79fe839b6a8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426830b0163a4ee687d760480ed1ef8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0862e3241b894c89bd32325d32fbab94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155e3c1ca4c34a2c91cadbc6328e9ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934676bac7fd435f913506b1b3540cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96a2bdf492341598100190eb019789d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb0e890ddf8499ebf6e2d3bc062d774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a107e43f6bb24a74916d129de82fad31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b480400bfb314c5cb013742973646d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e116d9d537438f887dbd87fc713654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1981a0d1962649b1929f2fec2ba948f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_params = [50, 1, 1, 0.0]\n",
    "\n",
    "for exp_params in tqdm(list_experiments):\n",
    "    for model_id in tqdm(range(5)):\n",
    "        one_id_experiment(model_id=model_id, nn_params=nn_params, **exp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adv data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b244d9bf804a379ed9c8006b9d9adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_id_experiment(model_id=0, nn_params=nn_params, **{'function': fgsm_attack, 'eps':0.03, 'n_steps':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_differences(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = 'results/Ford_A/Gegular/Discriminator_pickle/'\n",
    "\n",
    "exp_name = {'reg':'fgsm_attack_eps=0.3_nsteps=1', \n",
    "            'noreg': 'fgsm_reg_attack_eps=0.3_alpha=0.01_nsteps=1'}\n",
    "\n",
    "exp_disc_loss = {'reg':[],\n",
    "                 'noreg':[]}\n",
    "\n",
    "for exp_type in ['reg', 'noreg']:\n",
    "    for model_id in range(5):\n",
    "        with open(exp_path+exp_name[exp_type]+'/' + f\"{model_id}.pickle\", 'rb') as f:\n",
    "            exp = pickle.load(f)\n",
    "        exp_disc_loss[exp_type].append(exp.dict_logging['test']['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAus0lEQVR4nO3de3xU5Z348c8z19wTCCSEBAgYCNdwCQXvJd5AvNcbtrW41vpzK9vLb9tdu/6qbrvd1rZ2bau7rb3pqgvUWisqoiikdVVUhBAgEggYSLiGhNwzmdvz+2MmIZeZkGQmM5M53/frlVfOmfOcc77nZPKdM8888z1Ka40QQoj4Z4p2AEIIISJDEr4QQhiEJHwhhDAISfhCCGEQkvCFEMIgLNEOIJhx48bp/Pz8Ya/f1tZGcnJy+AIKM4kvNBJfaCS+0MRyfB9//PFprfX4gAu11jH5U1xcrEOxdevWkNYfaRJfaCS+0Eh8oYnl+IDtOkhelS4dIYQwCEn4QghhEJLwhRDCICThCyGEQUjCF0IIg5CEL4QQBiEJXwghDCIuE75Xe6MdghBCxJy4TPhPlT+FW7ujHYYQQsSUuEz4s8bOosZZE+0whBAipsRlwl+QtYBDnYeiHYYQQsSUuEz46fZ0Ojwd0Q5DCCFiSlwmfACUfHgrhBA9xW3Cz7ZkU91UHe0whBAiZsRtwj8v4Tw+PvVxtMMQQoiYEbcJf6xlLMdbj0c7DCGEiBlxm/CFEEL0FtcJPyspi5NtJ6MdhhBCxIS4TvgLsxays25ntMMQQoiYENcJf/qY6VSdqYp2GEIIERPiOuGblEnG4gshhF9cJ3yAFFsKLc6WaIchhBBRF/cJf/74+ZTXlUc7DCGEiLq4T/hzx81lz+k90Q5DCCGiLu4Tvt1sp9PTGe0whBAi6uI+4QNYTVZcHle0wxBCiKgyRMKfnTmbioaKaIchhBBRZYiEvyBrAWWnyqIdhhBCRJUhEn66PZ2mzqZohyGEEFFliIQPoJSSL2EJIQzNMAl/avpUuSGKEMLQDJPwF2UtYsepHdEOQwghosYwCX9iykSOtR6LdhhCCBE1YUn4SqkVSqlKpVSVUuqBAMsvVUrtUEq5lVK3hGOfQgghhibkhK+UMgNPAlcDs4E7lFKz+zQ7AtwF/E+o+wuF3BBFCGFk4bjCXwJUaa0Paa2dwDrghp4NtNbVWutyIKrDZOSGKEIII1Na69A24OuiWaG1vsc/fyewVGu9JkDbp4FXtdZ/CrKte4F7AbKzs4vXrVs37LhaW1tJSUnp9ZhXe3m96XWuybhm2NsNl0DxxRKJLzQSX2gkvuErKSn5WGu9ONAyS6SDGYjW+ingKYDFixfrZcuWDXtbpaWlBFp/z449LFs0/O2GS7D4YoXEFxqJLzQS38gIR5fOUWBSj/k8/2MxSW6IIoQwqnAk/I+A6UqpqUopG7AK2BCG7Y4IuSGKEMKoQk74Wms3sAZ4A/gE+KPWeq9S6ntKqesBlFKfUUrVArcCv1ZK7Q11v8MlN0QRQhhVWPrwtdYbgY19Hnuox/RH+Lp6ok5uiCKEMCrDfNO2J7khihDCiAyZ8OWGKEIIIzJkwpcbogghjMiQCT/dnk6zsznaYQghREQZMuF3kRuiCCGMxLAJX26IIoQwGsMmfLkhihDCaAyb8CemTOR42/FohyGEEBFj2IQPEGqlUCGEGE0MnfDlhihCCCMxdMKXG6IIIYzE0Al/+pjpVJ2pinYYQggREYZO+CZlQiP9+EIIYzB0wgdItibT6myNdhhCCDHiDJ/w54+fz666XdEOQwghRpzhE77cEEUIYRSGT/h2sx2n1xntMIQQYsQZPuEDWJRFbogihIh7kvCRG6IIIYxBEj5yQxQhhDFIwkduiCKEMIb4TPh7XiTz9EdDXk2KqQkh4ll8Jvy5N2P2tMN7T8Agk/jU9Kl82vTpCAcmhBDRE58JHziV/VnIvwjeeBA6z/1NWrkhihAi3sVtwgdg4kK4+Bvw1sPQMPDVu9wQRQgR7+I74QOkZMHyH0LZ83BwS7SjEUKIqIn/hA9gscFl/w+aj8EHTwXt1x+fOJ5T7aciHJwQQkSGMRJ+l4VfhJz5sPkhcHX0X5y1UPrxhRBxy1gJH2DyUjj/7+HN/weNNb0WyQ1RhBDxzHgJHyBtIlz1A/jot1D9bvfDckMUIUQ8M2bCB7AmwBWPwOlK+Pjp7n59uSGKECJehSXhK6VWKKUqlVJVSqkHAiy3K6XW+5d/oJTKD8d+Q6YULL4bxp4Hb38P3J1yQxSD01rT3uzE6XBHOxQhws4S6gaUUmbgSeBKoBb4SCm1QWvds/zkl4EzWusCpdQq4FHg9lD3HTZTL4ExU+CNB5l70dd4+sTrXJR7UbSjEiPE69W0nnHQVNdBc10HLWccaO3F63ZhMptJTk/G7fTQ2d6JxovJZMFitZCamUB6ViLp4xNJSLailIr2oQgxJCEnfGAJUKW1PgSglFoH3AD0TPg3AI/4p/8EPKGUUjqWitdkTIYrv4e99N9x2r0hbWp3aS0dLQFuqqIUtgQztgQLTUc0RyrqsSVYsCVacHY0UVf9CXU1n/LOmPNJS7QB4P3beqg7AiYTKBMohclsxmw2kzp1JlOv+hypCVbsrlYqXvgDNqsFi8Xse/eiz34icf7nbmdc3hS8Xs3ev23h0PZtaEB7ta+GkPZd3SampnPBrV+hs1nTVNfOzjf+jEkpbElJJCQlYU9Oxp6chD0pmYzsbJIzMs55PrTWvZLj6ZrDdDQ34XR04Ozw//ins/KnMn3JhQA0nz7Fe398vnsb/gkATpw8yYKZhWRMyAFgT+lbHNld1t3W43LjaHfQ2d6J1ZbB1OLb/Mu8bH/5e6DdeL1utMeN2+3q3u6VX1lDUckK3za3buaNX/0cAJPZjMlixWS2opQFpcwsuu5BTCYzSsGR8pdwdtRjT07AnphA3ek62sp99ZwmzSmi6PLlADSePMH/rn3m7CdFfY7rks/f1X1Muza/zuHdOwOe0/SsCXz2i3d3z2/42b8HPf9Fl68gf/4iAKrLd1L+1uvU1dXRvOO9fm2v++Z3uv9Wf33u9zSdOhFwm1PmLWD+lSu7j+md/3k66P4vuWN19zGVv7WJw/6/U/9jyubSL/xd9/wr//GjoNucd/ly8osWAnC4vIzyt14P2vbabz7QfUx/e/4PNJ0MfEyT5y1g/pVXnz2m5/8QdJu282Z1T+/a/Hr3c6+vtKzsXn+nV372w94Nevxf9DymkaJCzblKqVuAFVrre/zzdwJLtdZrerTZ429T658/6G9zus+27gXuBcjOzi5et27dsONqbW0lJSVl6CtqzZFjz1HrOjak1UxaYcOEHRPWg0tJZwva6UG7vCiXB4vLi3KDxoYmgU6PDae24vCA0+3Boz3d20pPnonVbAegqe0gLk/gzxRslnRSEvPRgNvbSUvbvqDxJSdMw2JJATw4Oo/T6WoIfBzKTEZiFmhw2aw0N9eidOAXQOf4PNyZuQCYWxqwHT+ENpnBbPYlMK8H5fWA10tH4ZLuJ7e9eg9mR1vAbVosY0i2TwKl8Hg6aO3YH/yYEguwmJMB6OisxemqD9jOrLxk2hvo+tc66cgE+l6daxSQYmkjyeLwbdNtp9mdEqCtT5b9tO91FUVD51jcOnA7q2UsSQmTAPB42mntODDAMU3HYk7y7d9Rg9Md5O9kSiQ1aUb3fFNr8G7IBHsedmsmAE5XPR2dtUHbpiUXdSfH1vb9eLz9hy9H4pg0mubW8hg+ph7PvRH4OyUWjSF3/uKgbQdSUlLysdY64MrhuMIPG631U8BTAIsXL9bLli0b9rZKS0sZ/volQ17D7XXT6emk09PJR49sYN5ND2FPTceekoY9JQOvxYwtNQ2lFMf2f8La734bOPsuwJaYiCnnPDILZnHdzdeTnDEGgKZTJ3B2dOD1eNBeL16vB6/Xi/Z4SExNY9zkfACcHe0cLi/D62/TRQEoxaTZ87q3WXf4U84cP9qdgBWqO6dZ7Qnkz19EaWkpF8+fz/u/+U/aTxzH5XbjSbDjTUvF5fXi7Gin+JobmXXxMgB2b32TN3/1C1+CD9D9/U8P/CP2JN8/yObfPEF97REsHi+qtRWLx4vNYiNx4kRyL7iI6Rd/FoCO1hYObv/g7LH0uBrat28fV9/xRZLS0gE4XlXJmeNnX6TNFgtmixWL1Yo9JYWcgsLuZU2nTvqW22xYLFbMVismszno31Zrjdfjxu104XE5cbt8v8fk5Ha3ObZ/H47WFjwuF26Xk4qKCmbNmoUCMiZMJGd6YfcxHd61o+uA+hyXYvK8+SSmpAJw8lBV0Ctse1IKU4oWdM/v3/a/QePPmlpARvYEwHfleurTKvbu3cucOXP6tZ2+9KLueA7vLqOzLfDFRnrWBLKnFQDgaG0N+k4EfFfOXcd04uCBAY4pufudSGlpKTn2q4NuM3tqQfe7hsaTJzh5KPhw6hnn9zim8jIcQY8pmwnnTe9xTGVBt1nT1MIVK3zxnTxURWOQdw325OReV+2V7/f8O/W+2O55TCMlHFf4FwCPaK2X++e/A6C1/mGPNm/427yvlLIAJ4DxA3XpLF68WG/fvn3YcYWW8EOz5cG1LPpaCTUV5dRW7KGmYjfj8ibzue/8KwBup5Mn/8+dTJ45m0mz55E3ex41ZFBxso3VF+ZHJea++p4/rTWumhra3nsf14njoBQJs2eTvHQp5rQ0vB4Pne1tODva6Wxvx2yxYE1IxJaYiC0hEWUy+dZ/fxuuY8dAQUJhIUlLl2IZOzbk+GKNxBcaiW/4lFIjeoX/ETBdKTUVOAqsAj7fp80GYDXwPnALsCWm+u/DqP5wLRVHNrDza8/3W9bVl22x2Sj60n2UlPjeSRxr7OCt96p54OqZkQ530JRS2CZPxjZ5MgDa48FR8QmNL7yAp7kFZbeRVLyY1IULSM/yXU266+po21JK80Hf1Zdt0iRSLr4Ia25u0P0IIUZOyAlfa+1WSq0B3gDMwO+11nuVUt8DtmutNwC/A55VSlUBDfheFOLSrldepdPZgj0pmUlzipg0ey55s+cxfnJ+ry6JrukOp4f/Kj3Ig9fMGlWjPpTZTOK8uSTOmwuAt6OD9h07qP/Nb9BOFyiwZI4j+fylpF17zag6NiHiVVj68LXWG4GNfR57qMe0A7g1HPuKdbWf7AbgsrvvY/YlA38WoLXmZ5srWXNZAQnW4H3Io4EpMZGUiy4i5SIZzipErIqpD23jwdTMJSz5/J1MKZp9zra/f7ealfNyyE5LiEBkQgijM25phRHi9topvHApialpA7YrO+VmbLKVhZPHRCgyIYTRScIfAefqr6461cLhZi83LcyLUERCCCEJP6zWP/RtDp18h5aG00HbNLW7eG7bEa6dZo1gZEIIIQk/bNqbGqmt/ISm1qMk+L9k0pfb4+Vnmyv55hUzMJtk1IoQIrIk4YdJ17fyMrKmYbXZA7Z5cutB7rwgn/QkuboXQkSeJPwwOVzu+2p5TuH8gMv/vKOWorx0CrKGUd9HCCHCQBJ+GGituxP+lADV7nYcOUNju4uSmVmRDk0IIbpJwg+D+tojtJ5pwGpOYNLsGb2WnWhy8Pru4/zdRfnRCU4IIfwk4YdB19V9WsYUUjLO9t87XB6e2HqAf7yqUEoLCCGiTr5pGwbnFS/FsW8fzXoayj/6RmvNf2zez/0lo79sghAiPsgVfhhkTMhhRmIaYwvO9t8/8141V83JJic9MYqRCSHEWZLww8Xt9t3pCXjnQB2pCVaKpwy9zrsQQowU6dIJ0a7NG2mprye7vR2z2ded88GhBr61vPAcawohRGTJFX6Iyt9+gw9eWk+DS5Eyxlf1Uj6fFULEIkn4IWhvbuLUpwcxmy2kTy8mNTOBE00OsqTcsRAiBknCD0FXOYXszPG40vNIHZtAWc0ZFk7KiGpcQggRiCT8EHSNv5+QmILDaydljJ19J1oonBC4eJoQQkSTJPxh6llOIScjE69XYzKb8Hg1VrOcViFE7JHMNEwNR2tobagnKT2Dscm+K3qPV8s3aoUQMUuGZQ6TMpmYW3IlVg228bkAHDjVwnSphimEiFFyhT9MYyfmsfy+r/OZwiKs02dgMinKjjSyQD6wFULEKEn4Ieo8cAD3+MkkZ9g52thB3hgppSCEiE1xmfBdzk5ajx8dse3X1x5h37t/pb25Cd3poK1Nkzq260tX0ocvhIhNcdeH39HawjPfup+Olhbar7mWpLT0sO+j4p2tfPiXFyi+5kbmAC31DtLyUki0SVVMIUTsirsr/MSUVLKmTMXrdrFj44YR2UfXcMzJs+aibHZaGjo51OagKDdjRPYnhBDhEHcJH+D8m1cBsHPTKzjaWsO67fbmJk5+ehCz1co4ix379AI8Hi97TjQzLy/87yaEECJc4jLhT5wxi9TcyTg72tm56ZWwbvvI7jLQmtyZc/Ae+hR7oa8qZmunm/REa1j3JYQQ4RSXCR8gp/h8AHZs3ICzoz1s2+2qnzNl3gJcR2uxTpwYtm0LIcRIituEnzJxErkzZ+NobaHszY1h2abWmmp//33+/EVorQFFW6dbKmQKIWJe3CZ8pRTn33Q7mXmTGTMxNyzb7GxrI3VMJsljxjJu0hQA2pud1LndUiFTCBHz4m5YZk9T5i9iddFClCk8r2sJKSl8/geP4XY68TY0YBk/npYGByfcbj4nFTKFEDEupEyolBqrlNqslDrg/z0mSLtNSqlGpdSroexvGPGFLdn3ZLHZcFTuJ6GwkOb6DjwJJqmQKYSIeaFmqQeAt7XW04G3/fOB/AS4M8R9DVvz6Tre+t1/sXvLm8Pehsftou5Itb/fHjorK7HPmEFzvQOS4/qNkhAiToSa8G8AnvFPPwPcGKiR1vptoCXEfQ3b8QOV7HrzNd5/cS0et2tY2zhW+Qn//e01vPD9BwHwtrViTk3l1JkOpk9MC2e4QggxIlTXFeuwVlaqUWud4Z9WwJmu+QBtlwHf0lpfO8D27gXuBcjOzi5et27dsGNrbW0lJcVXqlh7vVSsfxpHYwNTli1n3Kx5Q97e0Q/e4cSOD8gqKmbSRSUkb3iFtuuv46N33eQvNDE+aWivnT3ji0USX2gkvtBIfMNXUlLysdZ6caBl5+yLUEq9BUwIsOjBnjNaa62UGv6rh28bTwFPASxevFgvW7Zs2NsqLS2l5/rZVsXrTzxG0yflfO7er2IyD63uzXNvvAzAxddcT/6cIk7v3cv4ZcvYVfYRt1y9eMhF0/rGF2skvtBIfKEZSnwul4va2locDsfIBtVDeno6CQnRHYqdkJBAXl4eVuvgv/B5zoSvtb4i2DKl1EmlVI7W+rhSKgc4Neg9R9jMCy/l/Rf+h8aTx6l872/MuqRk0Ov6yilUYbZYyJs1h85PP8U+bVp3f75UyBQiempra0lNTSU/Pz9i/4stLS2kpkZvZJ7Wmvr6empra5k6deqg1wu1D38DsNo/vRp4OcTtjRiT2cySG28FYNtLf0R7vYNe98ieXf5yCrOx2hPorNyPvbCQhoYOLEnyga0Q0eRwOMjMzDTUhZdSiszMzCG/qwk14f8IuFIpdQC4wj+PUmqxUuq3PYJ7B3gBuFwpVauUWh7ifodl9qUlpI4bT8PRGmr37R30eofLywCYUrQIAGd1NbbJk9n5ST35k6VgmhDRZqRk32U4xxzS5anWuh64PMDj24F7esxfEsp+wsVssXLVV9aQmJZO9rSCQa93oqoSgClFCwHQXg/KYuHAp2dYedHkEYlVCCHCzXDfFspfUDykZA9w56O/4I7v/4SsKb37yjqbneTkxOYn9UKIyNq0aROFhYUUFBTwox/9KNrhBGS4hN/TyUNVDGZYqslsZuKMWSiTCU9jI+Z0XzeOcmlsidKHL4TReTwe7r//fl5//XUqKipYu3YtFRUV0Q6rH8Mm/Nd+8ROe+843OLxrx4DtPG53r3nHfl9JhRNNDpLskuyFEPDhhx9SUFDAtGnTsNlsrFq1ipdfjr0xLIbNWOOnTGXfu3/l/T+vZ8r8RQE/APG4XfzqvtVkTZnKTf/8MBabjc7K/aRds5J3as6QIyWRhYg5L2yvofZMR9i2lzcmkVsXTxqwzdGjR5k06WybvLw8Pvjgg7DFEC6GTfgLrlrJRxte5FhlBbUVu5k0p6hfm2P79+Foaaat8QwWmw0Az5kGLGPHsu/jSpam2CIdthDiHM6VnI3MsF06tsQkFq28HoBtf14fsM3Z4ZgL+y3zdHpJTJZbGgohIDc3l5qamu752tpacnPDcx+OcDJswgdYuOI6bIlJHNmzi2P7P+m3/HC5r38/v2s4pscDyoTHqzF1eEjLTIxovEKI2PSZz3yGAwcO8Omnn+J0Olm3bh3XX399tMPqx9AJPyE5hYUrrgP6X+V3tDRz4lBXOYW5ALhqarBNnsT+ky3k2qykZkofvhACLBYLTzzxBMuXL2fWrFncdtttzJkzJ9ph9WPYPvwui1Zez+4tbzA2dxJerweTyVdU7ciectCaiYWzsfqLJDn8JRV21TSSY7aQOlYSvhDCZ+XKlaxcuTLaYQzI8Ak/KS2drzz5Byx9Ks51def07L93HjpISskyjpZ+ylSvFbvc+EQIMYpIxoJ+yR7g/JtXMaGgkEmz53Y/5nU6MflH66CMWb9DCDF6xWUfftWp1iGv43G72b31Tf763O8BSBuXRdHlyxmT0/uT9rZON4m2odXSF0KIWBCXCX/vsSaqmzxDWqe9qZG3fvOfbH/1JeqP1vRb7mltw5SURHltE0W5GWGKVAghIicuE/7KeTl8eGJoCT81cxxzl10BWvP0//17tjz9a5pP13Uv7zywn4QZMyivbWRWVgpWu1zlCyFGl7hM+FazibEJisP1bUNab8mNt3RP73z9FZTpbB995/4D2AsLae10Q5tbRugIIUaduEz4AJfkWnjx49ohrZOeNaFXiYXUseO6p90nT2DJzgagpd4hY/CFEN3uvvtusrKymDt37rkbR1HcJny7RZFgM1Pf2jmk9Vb8/TfImTGTFV/9Zr9lJ5s7yU5LoKXeId+yFUJ0u+uuu9i0aVO0wzinuE34ALcvnsT67f0/gB1I2vgsPv/9nzLns2dv5NVVM7+s5gwLJmXQ3uIkMVXq6AghfC699FLGjh0b7TDOKa7H4Wem2HE4PbQ73STZhn+o7uPHseTksO9EC5fPymYH9TIGX4hYtfN5aDwSvu1lTIaFXwjf9qIorhM+wM3Fefzp41q+dEH+sLfhqKwkobAQzwmN1RzXb4qEGP3iJDmPhLjPXlMykzl6pgOXxzvsbXQeqMIy7Ty5qhdCjGpxn/ABrinKYePu48Ne39vRTlWLhxnZKbidHixWQ5w2IUScMUTmKsrLYHdt06BuWB5MWU0jCyZl0NLgIGWMDMkUQpx1xx13cMEFF1BZWUleXh6/+93voh1SQHHfh9/lkhnjeefAaS6dMX5I63k7OzHZbBxr7CA3I5GaTxpIkzH4Qoge1q5dG+0QBsUQV/gAl04fxzsH6s7dsI/OqipsBQWArzqmfOlKCDFaGSbhK6WYm5vO7tqmIa3Xuf8A3qkF3RUy25qcJKXbRyJEIYQYUYZJ+OArqvbq7mNDWsdVU8MnOqW7QqbWGpNJRusIIUYfQyV8q9lEbkbiEIuqacqPNVM0KX3E4hJCiEgwVMIHuKU4b8hF1Vo73aQlSCkFIcToZriEn2SzDLqomvv0acyZmd3zHrcXs1m6c4QQo5PhEj4Mvqiao7KSttx8stN8o3Jaz3TKGHwhRD81NTWUlJQwe/Zs5syZw89//vNohxRQSAlfKTVWKbVZKXXA/3tMgDYLlFLvK6X2KqXKlVK3h7LPcMhMsdPh9NDW6R6wXWflfioSslgwKQOAlgaH3PhECNGPxWLhscceo6Kigm3btvHkk09SUVER7bD6CfUK/wHgba31dOBt/3xf7cCXtNZzgBXA40qpjBD3O6DmTW9grawcsM0txXm8uGPgvnxvawsVLZrCCakAtNR3yBh8IUQ/OTk5LFq0CIDU1FRmzZrF0aNHoxxVf6F+0/YGYJl/+hmgFPjnng201vt7TB9TSp0CxgONIe47qNTlV2H+8U+o+8Uvybzny5iSkvq18RVVO4LL4w1aAVNrjVefrZDZeqaT5DEyBl+IWPaXqr9wrHVow68HMjFlIjcW3Djo9tXV1ezcuZOlS5eGLYZwCTXhZ2utu6qSnQCyB2qslFoC2ICDIe53QEopHEuXkDFrFqcef5y0FVeTtGhhv3ZdRdVuWJDbb5l2ucBk7lUh0+vVmKU8shAxbSjJOdxaW1u5+eabefzxx0lLS4taHMGocxUUU0q9BUwIsOhB4BmtdUaPtme01v368f3LcvC9A1ittd4WpM29wL0A2dnZxevWrRvEIQTW2tpKSkoKaE3C++9jPtNI21VXgrX38Mq1+zpZVWjrV/rYfOwYTQdrqShYxJIc3+viqd1esuaFJ+F3xxejJL7QSHyhGUp86enpFPjLn0SKx+PBbDb3eszlcnHrrbdyxRVXsGbNmojEUVVVRVNT7+oBJSUlH2utFwdcQWs97B+gEsjxT+cAlUHapQE7gFsGu+3i4mIdiq1bt/aad9bW6uPf/zfdXl7e6/HSylO6tPJUv/UbX3lVv/jnv+mahrbux7ZtOBhSTAPFF2skvtBIfKEZSnwVFRUjF0gQzc3Nvea9Xq++88479de//vWIxhHo2IHtOkheDfVydQOw2j+9Gni5bwOllA14CfhvrfWfQtzfsFlzc8n+l+/g2FvB6V8/hXY6AX9Rtf39i6o5q6upTsgkN8N3s3KvV0oqCCECe/fdd3n22WfZsmULCxYsYMGCBWzcuDHaYfUTah/+j4A/KqW+DBwGbgNQSi0G7tNa3+N/7FIgUyl1l3+9u7TWZSHue8iUycSYVbfjPHyYk4/+mIxbbyFh5kzm5aVTXttIUV7G2cZeD9p8tg+/rbGTZCmaJoQI4OKLLw7pfhuREtIVvta6Xmt9udZ6utb6Cq11g//x7f5kj9b6Oa21VWu9oMdPWRhiHzbblClk/8t3aN/+MfW/+z1XzxzHa33uiOV0e7srZAJSFlkIMeoZdsiJMpsZ+8UvkFKyjIaf/ITz2k51F1XzNDVx0mvtrpAJ8qUrIcToZ9iE38U+bRrZ33mAS5sOsv1nv0J7PHTu38+BlAm9KmRKwhdCjHaGT/gAymJhwpfvpnX2fKr/9d9oeestTo3P61Uh0+P2YpablwshRjHJYD1ce8MlvH7p7dimnYczNSPa4QghRFjFZcKvq2kZ1nqZKXY6vIqGy1Z2V8gUQoh4EZcJ/8yJNjoahjdE6pbiPB56eU93hUwA7dXICHwhRDAOh4MlS5Ywf/585syZw8MPPxztkAKKy4R/3sIsmmuGl/CnZCZTmJ3WXSEToL1FblwuhAjObrezZcsWdu3aRVlZGZs2bWLbtoAVZKIqLhO+2WLCZFU4Wl3DWv+h62b3qqDZUi8jdIQQwSmlumv/uFwuXC5Xv/pcsSDUb9rGrIx82LftOAuumBzytlrqHWTmxW6hKSHEWY1/fglXGGvRW3NzyfjcTeds5/F4KC4upqqqivvvvz8uyyPHLGuSor3eGZYaOC0NDvKLxoUpMiHESBpMch4JZrOZsrIyGhsbuemmm9izZw9z586NSizBxGWXTpf8okwO76kPeTsupwer3XzuhkIIw8vIyKCkpIRNmzZFO5R+4jrh5xRkcOxAY7TDEELEubq6OhobGwHo6Ohg8+bNzJw5M7pBBRC3XTrg+yAlIyuRMyfaGDMhOdrhCCHi1PHjx1m9ejUejwev18ttt93GtddeG+2w+onrhA8wY8kEdrx5mKXXTRvW+qOh5KkQIrqKiorYuXNntMM4p7ju0gGw2n017Z0O97DWd7S5SEyxnruhEELEuLhP+AAzPpPN/g9PDmtdXx38xDBHJIQQkWeIhJ+RnURTXcewumfkS1dCiHhhiIQPkDsjg2P7G4e8XkuD3OlKCBEfDJPwJ8/J5PDeoY/J7+xwY0+M+8+2hRAGYJiEbzIpktPttDQ4oh2KEEJEhWESPkDh+ROo/OBEtMMQQsQhj8fDwoULY3L8fRdDJfyEZCvuTg8elzfaoQgh4szPf/5zZs2aFe0wBmSohA9w3qIsqnacGlTbznaX9N8LIc6ptraW1157jXvuuSfaoQzIcNls/ORU9n90ksJBVC6VETpCjD6fvHeclvqOsG0vNTORWRfmDNjmG9/4Bj/+8Y9paRne7VUjxXAJHyBrciqnDjeTNSVtwHYyBl+I0edcyTncXn31VbKysiguLqa0tDSi+x4qw3XpAExbOJ6DO+vO2a653kGafMtWCDGAd999lw0bNpCfn8+qVavYsmULX/ziF6MdVkCGTPhmiwlbgpmOVueA7RxtLuzJhnwTJIQYpB/+8IfU1tZSXV3NunXruOyyy3juueeiHVZAhkz4ADPPz6Fy27mHaMbifSmFEGI4DHv5mpxhp7154FsgSqoXQgzFsmXLWLZsWbTDCMqwV/gA+fPGUV1+OtphCCFERBg64ecUpHP8YFPAZa5ODxab3MdWCBE/DJ3wlVKMyU7izIm2fst8dfBlSKYQIn6ElPCVUmOVUpuVUgf8v8cEaDNFKbVDKVWmlNqrlLovlH2G2/TPZLP/o/43R2mu75CEL4SIK6Fe4T8AvK21ng687Z/v6zhwgdZ6AbAUeEApNTHE/YZNsFsgtjbIl66EEPEl1IR/A/CMf/oZ4Ma+DbTWTq11p3/WHoZ9ht2MJdns71NFs73ZSVKaLUoRCSFE+Knh3Pave2WlGrXWGf5pBZzpmu/TbhLwGlAAfFtr/WSQ7d0L3AuQnZ1dvG7dumHH1traSkpKyqDbn9jpJXuB6h53f2q3l6x5I/faNNT4Ik3iC43EF5qhxJeenk5BQcEIR9Sbx+PBbD47qCMtLY3bbruN3/72twC43W6mT5/O4sWLeeGFF0YsjqqqKpqaeg88KSkp+VhrvTjgClrrAX+At4A9AX5uABr7tD1zjm1NBD4Ess+13+LiYh2KrVu3Dqn9p+V1umZfQ/f8BxsOhrT/cxlqfJEm8YVG4gvNUOKrqKgYuUCCaG5u7jWfnJys58+fr9vb27XWWm/cuFHPnz9fX3PNNSMaR6BjB7brIHn1nF+80lpfEWyZUuqkUipHa31cKZUDDFh3WGt9TCm1B7gE+NO59h1JU+Zk8v5LB8kr7Pe5sxBiFHns9uA3ILnyK2soumIFAOVvbWLzb54I2vYf1786pP2uXLmS1157jVtuuYW1a9dyxx138M477wDQ1tbGP/zDP7Bnzx5cLhePPPIIN9xwA9XV1dx55520tflGCj7xxBNceOGFlJaW8sgjjzBu3Dj27NlDcXExzz33XMjf/A+1z2IDsNo/vRp4uW8DpVSeUirRPz0GuBioDHG/YadMiuQM3y0Q3S4PZmvMfdQghIhhq1atYt26dTgcDsrLy1m69GwN9h/84AdcdtllfPjhh2zdupVvf/vbtLW1kZWVxebNm9mxYwfr16/na1/7Wvc6O3fu5PHHH6eiooJDhw7x7rvvhhxjqKUVfgT8USn1ZeAwcBuAUmoxcJ/W+h5gFvCYUkrjq1bwU6317hD3OyIKz5/Anr8epaA4i5QxMkJHiNFosFfmRVes6L7aD4eioiKqq6tZu3YtK1eu7LXszTffZMOGDfz0pz8FwOFwcOTIESZOnMiaNWsoKyvDbDazf//+7nWWLFlCXl4eAAsWLKC6upqLL744pBhDSvha63rg8gCPbwfu8U9vBopC2U+kJCRbcTs9nDnZLmPwhRBDdv311/Otb32L0tJS6uvrux/XWvPiiy9SWFjYq/0jjzxCdnY2u3btwuv1kpBwNu/Y7fbuabPZjNvde+j4cEi/RR8Fi7Mo23yENEn4Qoghuvvuu3n44YeZN29er8eXL1/OL3/5y67BK+zcuROApqYmcnJyMJlMPPvss3g8nhGNTxJ+H+PyUlEmRVK6/dyNhRCih7y8vF798F2++93v4nK5KCoqYs6cOXz3u98F4Ktf/SrPPPMM8+fPZ9++fSQnJ49ofIYtjzyQa+4vCloyWQgh+mptbe33WM9SyYmJifz617/u12b69OmUl5d3zz/66KP91gXf6J1wkCv8AKxSJVMIEYck4QshhEFIwhdCjHpdH4YayXCOWRK+EGJUS0hIoL6+3lBJX2tNfX19r2GcgyEf2gohRrW8vDxqa2upq6uL2D4dDseQk224JSQkdH8xa7Ak4QshRjWr1crUqVMjus/S0lIWLlwY0X2Gg3TpCCGEQUjCF0IIg5CEL4QQBhHSHa9GklKqDl8FzuEaB5wOUzgjQeILjcQXGokvNLEc3xSt9fhAC2I24YdKKbVdB7vNVwyQ+EIj8YVG4gtNrMcXjHTpCCGEQUjCF0IIg4jnhP9UtAM4B4kvNBJfaCS+0MR6fAHFbR++EEKI3uL5Cl8IIUQPkvCFEMIgRnXCV0qtUEpVKqWqlFIPBFhuV0qt9y//QCmVH8HYJimltiqlKpRSe5VSXw/QZplSqkkpVeb/eShS8fWIoVoptdu//+0Bliul1C/857BcKbUogrEV9jg3ZUqpZqXUN/q0ieg5VEr9Xil1Sim1p8djY5VSm5VSB/y/xwRZd7W/zQGl1OoIxvcTpdQ+/9/vJaVURpB1B3wujGB8jyiljvb4G64Msu6A/+8jGN/6HrFVK6XKgqw74ucvZFrrUfkDmIGDwDTABuwCZvdp81XgV/7pVcD6CMaXAyzyT6cC+wPEtwx4NcrnsRoYN8DylcDrgALOBz6I4t/7BL4vlUTtHAKXAouAPT0e+zHwgH/6AeDRAOuNBQ75f4/xT4+JUHxXARb/9KOB4hvMc2EE43sE+NYg/v4D/r+PVHx9lj8GPBSt8xfqz2i+wl8CVGmtD2mtncA64IY+bW4AnvFP/wm4XCkVkZvVaq2Pa613+KdbgE+A3EjsO8xuAP5b+2wDMpRSOVGI43LgoNY6lG9fh0xr/Tegoc/DPZ9nzwA3Blh1ObBZa92gtT4DbAZWRCI+rfWbWmu3f3YbMLSaumEU5PwNxmD+30M2UHz+3HEbsDbc+42U0Zzwc4GaHvO19E+o3W38T/gmIDMi0fXg70paCHwQYPEFSqldSqnXlVJzIhsZABp4Uyn1sVLq3gDLB3OeI2EVwf/Ron0Os7XWx/3TJ4DsAG1i5Tzeje8dWyDnei6MpDX+LqffB+kSi4XzdwlwUmt9IMjyaJ6/QRnNCX9UUEqlAC8C39BaN/dZvANfF8V84JfAXyIcHsDFWutFwNXA/UqpS6MQw4CUUjbgeuCFAItj4Rx207739jE51lkp9SDgBp4P0iRaz4X/As4DFgDH8XWbxKI7GPjqPub/l0Zzwj8KTOoxn+d/LGAbpZQFSAfqIxKdb59WfMn+ea31n/su11o3a61b/dMbAatSalyk4vPv96j/9yngJXxvnXsazHkeaVcDO7TWJ/suiIVzCJzs6uby/z4VoE1Uz6NS6i7gWuAL/helfgbxXBgRWuuTWmuP1toL/CbIfqN9/izA54D1wdpE6/wNxWhO+B8B05VSU/1XgKuADX3abAC6RkPcAmwJ9mQPN39/3++AT7TWPwvSZkLXZwpKqSX4/h6RfEFKVkqldk3j+3BvT59mG4Av+UfrnA809ei+iJSgV1bRPod+PZ9nq4GXA7R5A7hKKTXG32Vxlf+xEaeUWgH8E3C91ro9SJvBPBdGKr6enwndFGS/g/l/H0lXAPu01rWBFkbz/A1JtD81DuUH3wiS/fg+vX/Q/9j38D2xARLwdQNUAR8C0yIY28X43tqXA2X+n5XAfcB9/jZrgL34RhxsAy6M8Pmb5t/3Ln8cXeewZ4wKeNJ/jncDiyMcYzK+BJ7e47GonUN8LzzHARe+fuQv4/tc6G3gAPAWMNbfdjHw2x7r3u1/LlYBfxfB+Krw9X93PQ+7Rq5NBDYO9FyIUHzP+p9b5fiSeE7f+Pzz/f7fIxGf//Gnu55zPdpG/PyF+iOlFYQQwiBGc5eOEEKIIZCEL4QQBiEJXwghDEISvhBCGIQkfCGEMAhJ+EIIYRCS8IUQwiD+P2nsrIfHK1vEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "difference = np.array(exp_disc_loss['noreg']) - np.array(exp_disc_loss['reg'])\n",
    "iters = np.arange(len(difference[0]))\n",
    "\n",
    "for model_id in range(5):\n",
    "    plt.plot(iters, difference[model_id],linewidth=0.5, label=model_id)\n",
    "    \n",
    "diff_mean = np.mean(difference, axis=0)\n",
    "plt.plot(iters, diff_mean, linewidth=2, linestyle='--', label='Mean')    \n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = 'test_f1'\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "metrics_diff_list = list()\n",
    "\n",
    "for model_id in range(5):\n",
    "\n",
    "    plt.plot(iters, metric_diff, label=model_id)\n",
    "    \n",
    "    \n",
    "metrics_diff_mean = np.mean(np.array(metrics_diff_list), axis=0)\n",
    "plt.plot(iters, metrics_diff_mean, linewidth=2, linestyle='--', label='Mean')    \n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9acf173aaa4471988530a0169c4d50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79a372b960f4a379f6dd043e89611d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps = 0.03\n",
    "alpha = 0.001 \n",
    "\n",
    "n_steps = 1\n",
    "\n",
    "dataset = MyDataset\n",
    "criterion = torch.nn.BCELoss()\n",
    "batch_size = 256\n",
    "n_objects = y_train.shape[0]\n",
    "device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "train_mode=True\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "\n",
    "attack_fun = fgsm_attack\n",
    "attack_params = {'eps':eps}\n",
    "\n",
    "attack_fun_test = fgsm_attack\n",
    "attack_params_test = {'eps':eps}\n",
    "\n",
    "model_id = 0\n",
    "    \n",
    "path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "model.load_state_dict(copy.deepcopy(torch.load(model_path)))\n",
    "\n",
    "train_disc_loader = prepare_disc_data(model, train_loader, dataset, X_train_tensor, criterion, \n",
    "                                      attack_fun, attack_params, n_steps=n_steps, device=device, \n",
    "                                      batch_size=batch_size, train_mode=train_mode)\n",
    "\n",
    "\n",
    "test_disc_loader = prepare_disc_data(model, test_loader, dataset, X_test_tensor, criterion, \n",
    "                                     attack_fun_test, attack_params_test, n_steps=n_steps, device=device, \n",
    "                                     batch_size=batch_size, train_mode=train_mode)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4c3fdcd9e349148f703b4098c58e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c88cc7f4bd64933b6c98e5ebdb3a927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack_fun = fgsm_reg_attack\n",
    "attack_params = {'eps':eps, 'alpha':alpha}\n",
    "\n",
    "attack_fun_test = fgsm_reg_attack\n",
    "attack_params_test = {'eps':eps, 'alpha':alpha}\n",
    "\n",
    "\n",
    "path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "model.load_state_dict(copy.deepcopy(torch.load(model_path)))\n",
    "\n",
    "train_disc_loader_reg = prepare_disc_data(model, train_loader, dataset, X_train_tensor, criterion, \n",
    "                                      attack_fun, attack_params, n_steps=n_steps, device=device, \n",
    "                                      batch_size=batch_size, train_mode=train_mode)\n",
    "\n",
    "test_disc_loader_reg = prepare_disc_data(model, test_loader, dataset, X_test_tensor, criterion, \n",
    "                                     attack_fun_test, attack_params_test, n_steps=n_steps, device=device, \n",
    "                                     batch_size=batch_size, train_mode=train_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for training\n",
    "\n",
    "model_id = 0\n",
    "torch.manual_seed(model_id)\n",
    "\n",
    "device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "\n",
    "num_epochs = 20\n",
    "LR = 0.001\n",
    "step_lr = 12\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_procedure_log(model, train_loader, test_loader, criterion, optimizer, scheduler=None,\n",
    "                   num_epochs=30, step_print=5):\n",
    "    \n",
    "    dict_logging = {'test_acc':[], 'test_f1':[]}\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss = train_step(model, train_loader, criterion, device, optimizer, scheduler)\n",
    "        test_loss = valid_step(model, test_loader, criterion, device) \n",
    "\n",
    "        acc_train, pr_train, rec_train, f1_train = estimate_epoch(train_loader, model, device=device)\n",
    "        acc_test, pr_test, rec_test, f1_test = estimate_epoch(test_loader, model, device=device)\n",
    "        \n",
    "        dict_logging['test_acc'].append(acc_test)\n",
    "        dict_logging['test_f1'].append(f1_test)\n",
    "\n",
    "        if epoch % step_print == 0:\n",
    "            print(f'[Epoch {epoch + 1}] train loss: {train_loss:.3f}; acc_train {acc_train:.3f}; f1_train {f1_train:.3f}; test loss: {test_loss:.3f}; acc_test {acc_test:.3f}; f1_test {f1_test:.3f};')\n",
    "            \n",
    "    return model, dict_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c08d5952b1c4251816ce4ad7087ac34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75e5b3c71804c68901872d0ee3b84b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 0.693; acc_train 0.500; f1_train 0.666; test loss: 0.693; acc_test 0.499; f1_test 0.666;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4944386e8505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     model, dict_metrics_orig = train_procedure_log(model, train_disc_loader, test_disc_loader, \n\u001b[0m\u001b[1;32m     13\u001b[0m                              criterion, optimizer, num_epochs=num_epochs, step_print=20)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-4b9cfc6173df>\u001b[0m in \u001b[0;36mtrain_procedure_log\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs, step_print)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0macc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdict_logging\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c620c59f0206>\u001b[0m in \u001b[0;36mestimate_epoch\u001b[0;34m(loader, model, device, round_, multiclass)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0my_all_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcollate_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/cuda10/lib/python3.8/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict_metr_all_orig = dict()\n",
    "\n",
    "for model_id in tqdm(range(5)):\n",
    "    torch.manual_seed(model_id)\n",
    "\n",
    "    model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_lr, gamma=0.1)\n",
    "\n",
    "    model, dict_metrics_orig = train_procedure_log(model, train_disc_loader, test_disc_loader, \n",
    "                             criterion, optimizer, num_epochs=num_epochs, step_print=20)\n",
    "    \n",
    "    dict_metr_all_orig[model_id] = dict_metrics_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metr_all_reg = dict()\n",
    "\n",
    "for model_id in tqdm(range(5)):\n",
    "    torch.manual_seed(model_id)\n",
    "    \n",
    "    model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_lr, gamma=0.1)\n",
    "\n",
    "    model, dict_metrics_reg = train_procedure_log(model, train_disc_loader_reg, test_disc_loader_reg, \n",
    "                             criterion, optimizer, num_epochs=num_epochs, step_print=20)\n",
    "    dict_metr_all_reg[model_id] = dict_metrics_reg\n",
    "## reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: графики для 5 экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = 'test_f1'\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "metrics_diff_list = list()\n",
    "\n",
    "for model_id in range(5):\n",
    "    metric_orig = dict_metr_all_orig[model_id][metric_name]\n",
    "    metric_reg = dict_metr_all_reg[model_id][metric_name]\n",
    "    \n",
    "    iters = list(range(len(metric_reg)))\n",
    "    metric_diff = np.array(metric_orig) - np.array(metric_reg)\n",
    "    metrics_diff_list.append(metric_diff)\n",
    "    \n",
    "    plt.plot(iters, metric_diff, label=model_id)\n",
    "    \n",
    "    \n",
    "metrics_diff_mean = np.mean(np.array(metrics_diff_list), axis=0)\n",
    "plt.plot(iters, metrics_diff_mean, linewidth=2, linestyle='--', label='Mean')    \n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперимент с силой атаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do одношаговая iFGSM\n",
    "# to do взять более сильную alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_params = {'dataset': MyDataset(),\n",
    "                     'criterion': torch.nn.BCELoss(),\n",
    "                     'train_loader': train_loader,\n",
    "                     'test_loader': train_loader,\n",
    "                     \n",
    "                     ''}\n",
    "\n",
    "attack_fun = {'train': fgsm_attack,\n",
    "             'test': fgsm_attack\n",
    "             }\n",
    "\n",
    "\n",
    "attack_params = {'train': {'eps': eps, 'n_steps': n_steps},\n",
    "                'test': {'eps': eps, 'n_steps': n_steps},\n",
    "                }\n",
    "\n",
    "def experiment_disc(attack_fun: Dict,\n",
    "               attack_params: Dict,\n",
    "                    loaders: Dict,\n",
    "               model_for_attack,\n",
    "               model_disc,\n",
    "               train_params):\n",
    "    \n",
    "    train_disc_loader = prepare_disc_data(model, train_loader, dataset, criterion, \n",
    "                                      attack_fun, attack_params, n_steps=n_steps, device=device, \n",
    "                                      batch_size=batch_size, train_mode=train_mode)\n",
    "\n",
    "    test_disc_loader = prepare_disc_data(model, test_loader, dataset, criterion, \n",
    "                                     attack_fun_test, attack_params_test, n_steps=n_steps, device=device, \n",
    "                                     batch_size=batch_size, train_mode=train_mode)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.03\n",
    "alpha = 0.01 \n",
    "\n",
    "n_steps = 10\n",
    "\n",
    "dataset = MyDataset\n",
    "criterion = torch.nn.BCELoss()\n",
    "batch_size = 256\n",
    "n_objects = y_train.shape[0]\n",
    "device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "train_mode=True\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "\n",
    "attack_fun = fgsm_attack\n",
    "attack_params = {'eps':eps}\n",
    "\n",
    "attack_fun_test = fgsm_attack\n",
    "attack_params_test = {'eps':eps}\n",
    "\n",
    "model_id = 0\n",
    "    \n",
    "path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "model.load_state_dict(copy.deepcopy(torch.load(model_path)))\n",
    "\n",
    "train_disc_loader = prepare_disc_data(model, train_loader, dataset, X_train_tensor, criterion, \n",
    "                                      attack_fun, attack_params, n_steps=n_steps, device=device, \n",
    "                                      batch_size=batch_size, train_mode=train_mode)\n",
    "\n",
    "test_disc_loader = prepare_disc_data(model, test_loader, dataset, X_test_tensor, criterion, \n",
    "                                     attack_fun_test, attack_params_test, n_steps=n_steps, device=device, \n",
    "                                     batch_size=batch_size, train_mode=train_mode)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
