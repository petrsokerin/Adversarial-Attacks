{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from ignite.handlers.param_scheduler import create_lr_scheduler_with_warmup\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "\n",
    "from typing import Dict, Any, Tuple, List, Union, Sequence, Callable\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1,  1]), array([1846, 1755]))\n",
      "(array([-1,  1]), array([681, 639]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3601, 500), (1320, 500), (3601,), (1320,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'FordA'\n",
    "\n",
    "import sktime\n",
    "from sktime.datasets import load_from_tsfile\n",
    "\n",
    "x_train, y_train = load_from_tsfile(\"data/Ford_A/FordA_TRAIN.ts\")\n",
    "x_test, y_test = load_from_tsfile(\"data/Ford_A/FordA_TEST.ts\")\n",
    "\n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_X(X):\n",
    "    np_data = []\n",
    "    lens = []\n",
    "    for i in range(len(X)):\n",
    "        line = X.iloc[i, 0]\n",
    "        lens.append(len(line))\n",
    "        np_data.append(line)\n",
    "        \n",
    "    #print(np.mean(lens), np.std(lens))\n",
    "    return np.array(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36010, 50) (13200, 50) (36010, 1) (13200, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb3c91362b0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window = 50\n",
    "len_seq = x_train.shape[1]\n",
    "n_patches = len_seq//window\n",
    "\n",
    "X_train = np.vstack([x_train[:, i:i+window] for i in range(n_patches)])\n",
    "X_test = np.vstack([x_test[:, i:i+window] for i in range(n_patches)])\n",
    "\n",
    "y_train = np.array([(int(y)+1) // 2 for y in y_train])\n",
    "y_test = np.array([(int(y)+1) // 2 for y in y_test])\n",
    "\n",
    "y_train = np.vstack([y_train.reshape(-1, 1) for i in range(n_patches)])\n",
    "y_test = np.vstack([y_test.reshape(-1, 1) for i in range(n_patches)])\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "plt.plot(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor =torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, window=50):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.window=window\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        \n",
    "#         start_ind = np.random.randint(0, len(X) - self.window)\n",
    "#         X = X[start_ind:start_ind+self.window]\n",
    "        X = X.reshape([-1, 1])\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "BS = 64    \n",
    "train_loader = DataLoader(MyDataset(X_train, y_train), batch_size=BS, shuffle=True)\n",
    "test_loader = DataLoader(MyDataset(X_test, y_test), batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_layers, output_dim=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(1, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(data)\n",
    "        hidden = hidden.reshape(hidden.shape[1], hidden.shape[2])\n",
    "        \n",
    "        hidden = self.dropout(hidden)\n",
    "        output = self.relu(self.fc1(hidden))\n",
    "        output = self.fc2(self.dropout(output))\n",
    "        output = torch.sigmoid(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, loader, criterion, device, optimizer, scheduler=None):\n",
    "    losses, n_batches = 0, 0\n",
    "    model.train(True)\n",
    "    for x, labels in loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        labels = labels.reshape(-1, 1).to(device)\n",
    "        \n",
    "        y_out = model(x)\n",
    "        loss = criterion(y_out, labels) \n",
    "        \n",
    "        loss.backward()     \n",
    "        optimizer.step()\n",
    "        losses += loss\n",
    "        n_batches += 1\n",
    "\n",
    "    mean_loss = losses / n_batches\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    return mean_loss\n",
    "\n",
    "def valid_step(model, loader, criterion, device):\n",
    "    \n",
    "    losses, n_batches = 0, 0\n",
    "    model.eval()    \n",
    "    for x, labels in loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            labels = labels.reshape(-1, 1).to(device)\n",
    "\n",
    "            y_out = model(x)\n",
    "            loss = criterion(y_out, labels)\n",
    "            losses += loss\n",
    "\n",
    "            n_batches += 1\n",
    "\n",
    "    mean_loss = losses / n_batches\n",
    "    return mean_loss\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pr = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return acc, pr, rec, f1\n",
    "    \n",
    "def estimate_epoch(loader, model=None, device='cpu', round_=True, multiclass=False):\n",
    "    \n",
    "    y_all_pred = torch.tensor([])\n",
    "    y_all_true = torch.tensor([])\n",
    "    \n",
    "    for X, y_true in loader:\n",
    "        X = X.to(device)\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        if multiclass:\n",
    "            y_pred = torch.argmax(y_pred, axis=1)\n",
    "        else:\n",
    "            y_pred = torch.round(y_pred)\n",
    "        \n",
    "        y_all_true = torch.cat((y_all_true, y_true.cpu().detach()), dim=0)\n",
    "        y_all_pred = torch.cat((y_all_pred, y_pred.cpu().detach()), dim=0)\n",
    "        \n",
    "    y_all_pred = y_all_pred.numpy().reshape([-1, 1])\n",
    "    y_all_true = y_all_true.numpy().reshape([-1, 1])\n",
    "    \n",
    "    acc, pr, rec, f1 = calculate_metrics(y_all_true, y_all_pred)\n",
    "    \n",
    "    return acc, pr, rec, f1\n",
    "\n",
    "def train_procedure(model, train_loader, test_loader, criterion, optimizer, scheduler=None,\n",
    "                   num_epochs=30, step_print=5):\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss = train_step(model, train_loader, criterion, device, optimizer, scheduler)\n",
    "        test_loss = valid_step(model, test_loader, criterion, device) \n",
    "\n",
    "        acc_train, pr_train, rec_train, f1_train = estimate_epoch(train_loader, model, device=device)\n",
    "        acc_test, pr_test, rec_test, f1_test = estimate_epoch(test_loader, model, device=device)\n",
    "\n",
    "        if epoch % step_print == 0:\n",
    "            print(f'[Epoch {epoch + 1}] train loss: {train_loss:.3f}; acc_train {acc_train:.3f}; f1_train {f1_train:.3f}; test loss: {test_loss:.3f}; acc_test {acc_test:.3f}; f1_test {f1_test:.3f};')\n",
    "#             plt.hist(y_test_pred)\n",
    "#             plt.show()\n",
    "            \n",
    "    return model\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pr = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return acc, pr, rec, f1\n",
    "\n",
    "def plotting(y_true, y_pred, window=1000):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(y_true[-window:], label = 'True')\n",
    "    plt.plot(y_pred[-window:], label = 'Pred')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor =torch.tensor(X_test, dtype=torch.float32)\n",
    "X_train_tensor = X_train_tensor.reshape([X_train_tensor.shape[0],X_train_tensor.shape[1], 1])\n",
    "X_test_tensor = X_test_tensor.reshape([X_test_tensor.shape[0],X_test_tensor.shape[1], 1])\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "# #device = 'cpu'\n",
    "\n",
    "# num_epochs = 15\n",
    "# #print(num_epochs)\n",
    "# LR = 0.001\n",
    "\n",
    "# HIDDEN_DIM = 50\n",
    "# OUTPUT_DIM = 1\n",
    "# N_LAYERS = 1\n",
    "# DROPOUT = 0.3\n",
    "\n",
    "# for model_id in range(5):\n",
    "#     print(model_id)\n",
    "#     torch.manual_seed(model_id)\n",
    "\n",
    "#     model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "\n",
    "#     criterion = torch.nn.BCELoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 12, gamma=0.1)\n",
    "    \n",
    "#     model = train_procedure(model, train_loader, test_loader, criterion, optimizer,\n",
    "#                 num_epochs=15, step_print=5)\n",
    "    \n",
    "#     torch.save(model.state_dict(), f'checkpoints/Ford_A/model_{model_id}_{col}.pth') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting adv Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(loss_val, x, eps):\n",
    "    \n",
    "    grad_ = torch.autograd.grad(loss_val, x, retain_graph=True)[0]\n",
    "    x_adv = x.data + eps * torch.sign(grad_)\n",
    "    return x_adv\n",
    "    \n",
    "def fgsm_reg_attack(loss_val, x, eps, alpha):\n",
    "    \n",
    "    x_anchor = x[:, 1:-1]\n",
    "    x_left = x[:, 2:]\n",
    "    x_right = x[:, :-2]\n",
    "    x_regular = (x_left + x_right) / 2\n",
    "    loss_reg = torch.sum((x_anchor - x_regular.detach()) ** 2, dim=list(range(1, len(x.shape))))\n",
    "    \n",
    "    loss = loss_val - alpha * torch.mean(loss_reg)\n",
    "    grad_ = torch.autograd.grad(loss, x, retain_graph=True)[0]\n",
    "    x_adv = x.data + eps * (torch.sign(grad_))\n",
    "\n",
    "    return x_adv\n",
    "\n",
    "\n",
    "def attack_one_iter(\n",
    "        model: nn.Module,  # model for attack\n",
    "        loader: DataLoader,  # dataloader with data\n",
    "        criterion: nn.Module,\n",
    "        attack_fun,\n",
    "        attack_params,\n",
    "        device='cpu',\n",
    "        train_mode=False):  # params_dict with eps and iter number\n",
    "\n",
    "    \"\"\"\n",
    "    Applies 1 iteration of ifgsm adversarial attack to data\n",
    "    :param model: model to get grad\n",
    "    :param loader: dataloader with data\n",
    "    :param criterion: loss function to calculate gradient for attack\n",
    "    :param eps: the strengh of attack\n",
    "    :param train_mode: bool to change mode of the model: should be False,\n",
    "                       but RNN layers can't calculate grad with False value, so need to be set as True\n",
    "    :return: x_adv_tensor - adversarial data,\n",
    "            all_y_true - true labels,\n",
    "            all_preds - predinctions before attack,\n",
    "            all_preds_adv - predinctions on attacked data\n",
    "    \"\"\"\n",
    "    model.train(train_mode)\n",
    "    req_grad(model, state=False)  # detach all model's parameters\n",
    "\n",
    "    all_y_true = []  # logging y_true for rebuilding dataloader and calculation difference with preds\n",
    "    all_preds = []  # logging predictions original for calculation difference with data\n",
    "    all_preds_adv = []  # logging predictions for calculation difference with data\n",
    "    x_adv_tensor = torch.FloatTensor([])  # logging x_adv for rebuilding dataloader\n",
    "\n",
    "    for x, y_true in loader:\n",
    "        all_y_true.extend(y_true.detach().data.numpy())\n",
    "\n",
    "        x.grad = None\n",
    "        x.requires_grad = True\n",
    "\n",
    "        # prediction for original input\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "\n",
    "        # attack for adv input\n",
    "        loss_val = criterion(y_pred, y_true.reshape(-1, 1))\n",
    "        x_adv = attack_fun(loss_val, x, **attack_params)\n",
    "        x_adv_tensor = torch.cat((x_adv_tensor, x_adv.cpu().detach()), dim=0)\n",
    "\n",
    "        # assert (x_adv == x).sum() == 0, \"Data doesn't change after attack\"\n",
    "        all_preds.extend(y_pred.cpu().detach().data.numpy())\n",
    "\n",
    "        # prediction for adv input\n",
    "        with torch.no_grad():\n",
    "            y_pred_adv = model(x_adv)\n",
    "            all_preds_adv.extend(y_pred_adv.cpu().detach().data.numpy())\n",
    "\n",
    "        # assert (y_pred_adv == y_pred).sum() == 0, \"Predicitions doesn't change after attack\"\n",
    "\n",
    "    return x_adv_tensor, all_y_true, all_preds, all_preds_adv\n",
    "\n",
    "\n",
    "def attack_iterations_data(model: nn.Module,\n",
    "                     loader: DataLoader,\n",
    "                     dataset_class: Dataset,\n",
    "                     criterion: nn.Module,\n",
    "                     attack_fun,\n",
    "                     attack_params,\n",
    "                     n_steps: int,\n",
    "                     device='cpu',\n",
    "                     train_mode=False,\n",
    "                     ):\n",
    "\n",
    "    for iter_ in tqdm(range(n_steps)):\n",
    "\n",
    "        # attack\n",
    "        x_adv_tensor, y_true, preds_original, preds_adv = attack_one_iter(model=model, \n",
    "                                                                          loader=loader, \n",
    "                                                                          criterion=criterion, \n",
    "                                                                          attack_fun=attack_fun,\n",
    "                                                                          attack_params=attack_params, \n",
    "                                                                          device=device, \n",
    "                                                                          train_mode=train_mode)\n",
    "\n",
    "        # rebuilding dataloader for new iteration\n",
    "        it_dataset = dataset_class(x_adv_tensor, torch.tensor(y_true))\n",
    "        loader = DataLoader(it_dataset, batch_size=loader.batch_size)\n",
    "\n",
    "    return torch.tensor(x_adv_tensor).detach(), torch.tensor(y_true).detach()\n",
    "\n",
    "\n",
    "def req_grad(model: nn.Module, state: bool = True) -> None:\n",
    "    \"\"\"Set requires_grad of all model parameters to the desired value.\n",
    "\n",
    "    :param model: the model\n",
    "    :param state: desired value for requires_grad\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(state)\n",
    "\n",
    "def prepare_adv_data(\n",
    "        model: nn.Module,  # model for attack\n",
    "        loader: DataLoader,  # dataloader with data\n",
    "        criterion: nn.Module,\n",
    "        attack_func,\n",
    "        attack_params,\n",
    "        device='cpu',\n",
    "        train_mode=False):  # params_dict with eps and iter number\n",
    "\n",
    "    model.train(train_mode)\n",
    "    req_grad(model, state=False)  # detach all model's parameters\n",
    "\n",
    "    all_y_true = torch.tensor([]) # logging y_true for rebuilding dataloader and calculation difference with preds\n",
    "    x_adv_tensor = torch.FloatTensor([])  # logging x_adv for rebuilding dataloader\n",
    "\n",
    "    for x, y_true in loader:\n",
    "        \n",
    "        all_y_true = torch.cat((all_y_true, y_true.cpu().detach()), dim=0)\n",
    "        x.grad = None\n",
    "        x.requires_grad = True\n",
    "\n",
    "        # prediction for original input\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # attack for adv input\n",
    "        loss_val = criterion(y_pred, y_true.reshape(-1, 1))\n",
    "        x_adv = attack_fun(loss_val, x, **attack_params)\n",
    "        x_adv_tensor = torch.cat((x_adv_tensor, x_adv.cpu().detach()), dim=0)\n",
    "\n",
    "    return x_adv_tensor.detach(), all_y_true.detach()\n",
    "\n",
    "\n",
    "def prepare_disc_data(model, \n",
    "                      loader, \n",
    "                      dataset_class,\n",
    "                      X_tensor, \n",
    "                      criterion,\n",
    "                      attack_fun,\n",
    "                      attack_params, \n",
    "                      n_steps,\n",
    "                      device, \n",
    "                      batch_size,\n",
    "                      train_mode=True):\n",
    "    \n",
    "\n",
    "    X_adv, y_adv = attack_iterations_data(model, loader, dataset_class, criterion, attack_fun, attack_params,\n",
    "                                          n_steps, device, batch_size, train_mode=train_mode)\n",
    "    \n",
    "    \n",
    "    disc_labels_zeros = torch.zeros((len(X_tensor), 1)) #True label class\n",
    "    disc_labels_ones = torch.ones(y_adv.shape) #True label class\n",
    "    \n",
    "    new_x = torch.concat([X_tensor, X_adv], dim=0)\n",
    "    new_y = torch.concat([disc_labels_zeros, disc_labels_ones], dim=0)\n",
    "    \n",
    "    disc_loader = DataLoader(dataset_class(new_x, new_y), batch_size=BS, shuffle=True)\n",
    "    \n",
    "    return disc_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-9244b749d221>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-9244b749d221>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    if 'alpha' in\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class HideAttackExp:\n",
    "    def __init__(self, attack_model, train_loader, test_loader, attack_train_params, \n",
    "                 attack_test_params, discriminator_model, disc_train_params, multiclass=False):\n",
    "        \n",
    "        self.attack_loaders = {'train': train_loader,\n",
    "                       'test': test_loader}\n",
    "        self.attack_train = {'train':IterGradAttack(attack_model, train_loader, **attack_train_params),\n",
    "                             'test': IterGradAttack(attack_model, test_loader, **attack_test_params)}\n",
    "        self.disc_loaders = dict()\n",
    "        \n",
    "        self.attack_train_params = attack_train_params\n",
    "        self.attack_test_params = attack_test_params\n",
    "        \n",
    "        #TO DO\n",
    "        self.eps = attack_train_params\n",
    "        self.alpha = None\n",
    "        if 'alpha' in \n",
    "        self.n_iters = n_iters\n",
    "        self.multiclass = multiclass\n",
    "        \n",
    "        self.attack_model = attack_model\n",
    "        self.disc_model = discriminator_model\n",
    "        \n",
    "        self.disc_criterion = torch.nn.BCELoss()\n",
    "        self_disc_n_epoch = disc_train_params['n_epoch']\n",
    "        self.disc_batch_size = 64\n",
    "        self.disc_optimizer = disc_train_params['optimizer']\n",
    "        if 'scheduler' in disc_train_params.keys():\n",
    "            self.disc_scheduler = disc_train_params['scheduler']\n",
    "        else:\n",
    "            self.disc_scheduler = None\n",
    "\n",
    "        self.attack_device = next(classic_model.parameters()).device\n",
    "        self.disc_device = next(discriminator_model.parameters()).device\n",
    "    \n",
    "    def _generate_adv_data(self, mode='train', batch_size=64):\n",
    "        \n",
    "        self.disc_batch_size = batch_size\n",
    "\n",
    "        X_adv, y_adv = self.attack_train[mode].run_iterations()\n",
    "        X_orig = self.loaders[mode].dataset.X\n",
    "    \n",
    "        disc_labels_zeros = torch.zeros((len(X_orig), 1)) #True label class\n",
    "        disc_labels_ones = torch.ones(y_adv.shape) #True label class\n",
    "\n",
    "        new_x = torch.concat([X_orig, X_adv], dim=0)\n",
    "        new_y = torch.concat([disc_labels_zeros, disc_labels_ones], dim=0)\n",
    "\n",
    "        suffle_status = mode == 'train'\n",
    "        disc_loader = DataLoader(dataset_class(new_x, new_y), batch_size=batch_size, shuffle=suffle_status)\n",
    "        self.disc_loaders[mode] = disc_loader\n",
    "        return disc_loader\n",
    "    \n",
    "    def get_disc_dataloaders(self):\n",
    "        self._generate_adv_data('train')\n",
    "        self._generate_adv_data('test')\n",
    "        \n",
    "    def _logging_train_disc(self, data, mode='train'):\n",
    "        \n",
    "        for metric in self.dict_logging[mode].keys():\n",
    "            self.dict_logging[mode][metric].append(data[metric])\n",
    "    \n",
    "    def train_discriminator(self):\n",
    "        metric_names = ['loss', 'accuracy', 'precision', 'recall', 'f1', 'balance']\n",
    "        self.dict_logging = {'train': {metric:[] for metric in metric_names},\n",
    "                       'test': {metric:[] for metric in metric_names}}\n",
    "\n",
    "        for epoch in tqdm(range(self.disc_num_epochs)):\n",
    "            train_metrics_epoch = self._train_step()\n",
    "            train_metrics_epoch = {met_name:met_val for met_name, met_val\n",
    "                                   in zip(metric_names, train_metrics_epoch)}\n",
    "            self._logging_train_disc(train_metrics_epoch, mode='train')\n",
    "            \n",
    "            test_metrics_epoch = self._valid_step() \n",
    "            test_metrics_epoch = {met_name:met_val for met_name, met_val \n",
    "                       in zip(metric_names, test_metrics_epoch)}\n",
    "            self._logging_train_disc(test_metrics_epoch, mode='test')\n",
    "            \n",
    "    \n",
    "    def _train_step(self):\n",
    "        losses, n_batches = 0, 0\n",
    "        \n",
    "        y_all_pred = torch.tensor([])\n",
    "        y_all_true = torch.tensor([])\n",
    "        \n",
    "        model.train(True)\n",
    "        for x, labels in self.disc_loaders['train']:\n",
    "\n",
    "            self.disc_optimizer.zero_grad()\n",
    "            x = x.to(self.disc_device)\n",
    "            labels = labels.reshape(-1, 1).to(self.disc_device)\n",
    "\n",
    "            y_out = self.disc_model(x)\n",
    "            \n",
    "            loss = self.disc_criterion(y_out, labels) \n",
    "\n",
    "            loss.backward()     \n",
    "            self.disc_optimizer.step()\n",
    "            losses += loss\n",
    "            n_batches += 1\n",
    "            \n",
    "            if multiclass:\n",
    "                y_pred = torch.argmax(y_pred, axis=1)\n",
    "            else:\n",
    "                y_pred = torch.round(y_pred)\n",
    "\n",
    "            y_all_true = torch.cat((y_all_true, y_true.cpu().detach()), dim=0)\n",
    "            y_all_pred = torch.cat((y_all_pred, y_pred.cpu().detach()), dim=0)\n",
    "\n",
    "        mean_loss = losses / n_batches\n",
    "\n",
    "        if self.disc_scheduler:\n",
    "            self.disc_scheduler.step()\n",
    "            \n",
    "        y_all_pred = y_all_pred.numpy().reshape([-1, 1])\n",
    "        y_all_true = y_all_true.numpy().reshape([-1, 1])\n",
    "\n",
    "        acc, pr, rec, f1 = self.calculate_metrics(y_all_true, y_all_pred)\n",
    "        balance = np.sum(y_all_pred) / len(y_all_pred)\n",
    "        return mean_loss, acc, pr, rec, f1, balance\n",
    "\n",
    "\n",
    "    def _valid_step(self):\n",
    "        \n",
    "        y_all_pred = torch.tensor([])\n",
    "        y_all_true = torch.tensor([])\n",
    "        \n",
    "        losses, n_batches = 0, 0\n",
    "        model.eval()    \n",
    "        for x, labels in self.disc_loaders['test']:\n",
    "            with torch.no_grad():\n",
    "                x = x.to(self.disc_device)\n",
    "                labels = labels.reshape(-1, 1).to(self.disc_device)\n",
    "\n",
    "                y_out = self.disc_model(x)\n",
    "                loss = self.disc_criterion(y_out, labels)\n",
    "                losses += loss\n",
    "\n",
    "                n_batches += 1\n",
    "\n",
    "        mean_loss = losses / n_batches\n",
    "        \n",
    "        y_all_pred = y_all_pred.numpy().reshape([-1, 1])\n",
    "        y_all_true = y_all_true.numpy().reshape([-1, 1])\n",
    "\n",
    "        acc, pr, rec, f1 = self.calculate_metrics(y_all_true, y_all_pred)\n",
    "        balance = np.sum(y_all_pred) / len(y_all_pred)\n",
    "        return mean_loss, acc, pr, rec, f1, balance\n",
    "\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred):\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        pr = precision_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        return acc, pr, rec, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attack model loading\n",
    "model_id = 0\n",
    "path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "\n",
    "device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "attack_model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "attack_model.load_state_dict(copy.deepcopy(torch.load(model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_train_params = {'attack_func':fgsm_attack, \n",
    "                     'attack_params':{'eps':0.03}, \n",
    "                     'criterion':torch.nn.BCELoss(), \n",
    "                     'n_steps':10}\n",
    "attack_test_params = attack_train_params\n",
    "\n",
    "\n",
    "\n",
    "experiment = HideAttackExp(attack_model, train_loader, test_loader, attack_train_params, \n",
    "                           attack_test_params, discriminator_model, disc_train_params):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "attack_iterations_data() got multiple values for argument 'train_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e49734635b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m train_disc_loader = prepare_disc_data(model, train_loader, dataset, X_train_tensor, criterion, \n\u001b[0m\u001b[1;32m     33\u001b[0m                                       \u001b[0mattack_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                       batch_size=batch_size, train_mode=train_mode)\n",
      "\u001b[0;32m<ipython-input-16-9931abf2f09e>\u001b[0m in \u001b[0;36mprepare_disc_data\u001b[0;34m(model, loader, dataset_class, X_tensor, criterion, attack_fun, attack_params, n_steps, device, batch_size, train_mode)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     X_adv, y_adv = attack_iterations_data(model, loader, dataset_class, criterion, attack_fun, attack_params,\n\u001b[0m\u001b[1;32m    169\u001b[0m                                           n_steps, device, batch_size, train_mode=train_mode)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: attack_iterations_data() got multiple values for argument 'train_mode'"
     ]
    }
   ],
   "source": [
    "eps = 0.03\n",
    "alpha = 0.001 \n",
    "\n",
    "n_steps = 1\n",
    "\n",
    "dataset = MyDataset\n",
    "criterion = torch.nn.BCELoss()\n",
    "batch_size = 256\n",
    "n_objects = y_train.shape[0]\n",
    "device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "train_mode=True\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "\n",
    "attack_fun = fgsm_attack\n",
    "attack_params = {'eps':eps}\n",
    "\n",
    "attack_fun_test = fgsm_attack\n",
    "attack_params_test = {'eps':eps}\n",
    "\n",
    "model_id = 0\n",
    "    \n",
    "path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "model.load_state_dict(copy.deepcopy(torch.load(model_path)))\n",
    "\n",
    "train_disc_loader = prepare_disc_data(model, train_loader, dataset, X_train_tensor, criterion, \n",
    "                                      attack_fun, attack_params, n_steps=n_steps, device=device, \n",
    "                                      batch_size=batch_size, train_mode=train_mode)\n",
    "\n",
    "test_disc_loader = prepare_disc_data(model, test_loader, dataset, X_test_tensor, criterion, \n",
    "                                     attack_fun_test, attack_params_test, n_steps=n_steps, device=device, \n",
    "                                     batch_size=batch_size, train_mode=train_mode)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc8371e2a784a4ca5d6b8462a8860cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862423d2adc5427aae812b8e29732a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack_fun = fgsm_reg_attack\n",
    "attack_params = {'eps':eps, 'alpha':alpha}\n",
    "\n",
    "attack_fun_test = fgsm_reg_attack\n",
    "attack_params_test = {'eps':eps, 'alpha':alpha}\n",
    "\n",
    "\n",
    "path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "model.load_state_dict(copy.deepcopy(torch.load(model_path)))\n",
    "\n",
    "train_disc_loader_reg = prepare_disc_data(model, train_loader, dataset, X_train_tensor, criterion, \n",
    "                                      attack_fun, attack_params, n_steps=n_steps, device=device, \n",
    "                                      batch_size=batch_size, train_mode=train_mode)\n",
    "\n",
    "test_disc_loader_reg = prepare_disc_data(model, test_loader, dataset, X_test_tensor, criterion, \n",
    "                                     attack_fun_test, attack_params_test, n_steps=n_steps, device=device, \n",
    "                                     batch_size=batch_size, train_mode=train_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for training\n",
    "\n",
    "model_id = 0\n",
    "torch.manual_seed(model_id)\n",
    "\n",
    "device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "\n",
    "num_epochs = 20\n",
    "LR = 0.001\n",
    "step_lr = 12\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_procedure_log(model, train_loader, test_loader, criterion, optimizer, scheduler=None,\n",
    "                   num_epochs=30, step_print=5):\n",
    "    \n",
    "    dict_logging = {'test_acc':[], 'test_f1':[]}\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss = train_step(model, train_loader, criterion, device, optimizer, scheduler)\n",
    "        test_loss = valid_step(model, test_loader, criterion, device) \n",
    "\n",
    "        acc_train, pr_train, rec_train, f1_train = estimate_epoch(train_loader, model, device=device)\n",
    "        acc_test, pr_test, rec_test, f1_test = estimate_epoch(test_loader, model, device=device)\n",
    "        \n",
    "        dict_logging['test_acc'].append(acc_test)\n",
    "        dict_logging['test_f1'].append(f1_test)\n",
    "\n",
    "        if epoch % step_print == 0:\n",
    "            print(f'[Epoch {epoch + 1}] train loss: {train_loss:.3f}; acc_train {acc_train:.3f}; f1_train {f1_train:.3f}; test loss: {test_loss:.3f}; acc_test {acc_test:.3f}; f1_test {f1_test:.3f};')\n",
    "            \n",
    "    return model, dict_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09220772a56948759d4cb0be291bee7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c767f7874b94441bc25fb43738e07f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 0.693; acc_train 0.500; f1_train 0.667; test loss: 0.693; acc_test 0.500; f1_test 0.667;\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29f02fd3cd242d89543c365adc26db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 0.693; acc_train 0.500; f1_train 0.667; test loss: 0.693; acc_test 0.500; f1_test 0.667;\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028ed0d4ba8a4d35831b74fa19a9bbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 0.694; acc_train 0.500; f1_train 0.664; test loss: 0.693; acc_test 0.500; f1_test 0.664;\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bf6fdc0bdc442482662037d4163708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 0.693; acc_train 0.500; f1_train 0.418; test loss: 0.693; acc_test 0.500; f1_test 0.410;\n"
     ]
    }
   ],
   "source": [
    "dict_metr_all_orig = dict()\n",
    "\n",
    "for model_id in tqdm(range(5)):\n",
    "    torch.manual_seed(model_id)\n",
    "\n",
    "    model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_lr, gamma=0.1)\n",
    "\n",
    "    model, dict_metrics_orig = train_procedure_log(model, train_disc_loader, test_disc_loader, \n",
    "                             criterion, optimizer, num_epochs=num_epochs, step_print=20)\n",
    "    \n",
    "    dict_metr_all_orig[model_id] = dict_metrics_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metr_all_reg = dict()\n",
    "\n",
    "for model_id in tqdm(range(5)):\n",
    "    torch.manual_seed(model_id)\n",
    "    \n",
    "    model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_lr, gamma=0.1)\n",
    "\n",
    "    model, dict_metrics_reg = train_procedure_log(model, train_disc_loader_reg, test_disc_loader_reg, \n",
    "                             criterion, optimizer, num_epochs=num_epochs, step_print=20)\n",
    "    dict_metr_all_reg[model_id] = dict_metrics_reg\n",
    "## reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:   5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = 'test_f1'\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "metrics_diff_list = list()\n",
    "\n",
    "for model_id in range(5):\n",
    "    metric_orig = dict_metr_all_orig[model_id][metric_name]\n",
    "    metric_reg = dict_metr_all_reg[model_id][metric_name]\n",
    "    \n",
    "    iters = list(range(len(metric_reg)))\n",
    "    metric_diff = np.array(metric_orig) - np.array(metric_reg)\n",
    "    metrics_diff_list.append(metric_diff)\n",
    "    \n",
    "    plt.plot(iters, metric_diff, label=model_id)\n",
    "    \n",
    "    \n",
    "metrics_diff_mean = np.mean(np.array(metrics_diff_list), axis=0)\n",
    "plt.plot(iters, metrics_diff_mean, linewidth=2, linestyle='--', label='Mean')    \n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do  iFGSM\n",
    "# to do    alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_params = {'dataset': MyDataset(),\n",
    "                     'criterion': torch.nn.BCELoss(),\n",
    "                     'train_loader': train_loader,\n",
    "                     'test_loader': train_loader,\n",
    "                     \n",
    "                     ''}\n",
    "\n",
    "attack_fun = {'train': fgsm_attack,\n",
    "             'test': fgsm_attack\n",
    "             }\n",
    "\n",
    "\n",
    "attack_params = {'train': {'eps': eps, 'n_steps': n_steps},\n",
    "                'test': {'eps': eps, 'n_steps': n_steps},\n",
    "                }\n",
    "\n",
    "def experiment_disc(attack_fun: Dict,\n",
    "               attack_params: Dict,\n",
    "                    loaders: Dict,\n",
    "               model_for_attack,\n",
    "               model_disc,\n",
    "               train_params):\n",
    "    \n",
    "    train_disc_loader = prepare_disc_data(model, train_loader, dataset, criterion, \n",
    "                                      attack_fun, attack_params, n_steps=n_steps, device=device, \n",
    "                                      batch_size=batch_size, train_mode=train_mode)\n",
    "\n",
    "    test_disc_loader = prepare_disc_data(model, test_loader, dataset, criterion, \n",
    "                                     attack_fun_test, attack_params_test, n_steps=n_steps, device=device, \n",
    "                                     batch_size=batch_size, train_mode=train_mode)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.03\n",
    "alpha = 0.01 \n",
    "\n",
    "n_steps = 10\n",
    "\n",
    "dataset = MyDataset\n",
    "criterion = torch.nn.BCELoss()\n",
    "batch_size = 256\n",
    "n_objects = y_train.shape[0]\n",
    "device= torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "train_mode=True\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "\n",
    "attack_fun = fgsm_attack\n",
    "attack_params = {'eps':eps}\n",
    "\n",
    "attack_fun_test = fgsm_attack\n",
    "attack_params_test = {'eps':eps}\n",
    "\n",
    "model_id = 0\n",
    "    \n",
    "path_to_saves = 'checkpoints/Ford_A/'\n",
    "\n",
    "model = LSTM_net(HIDDEN_DIM, N_LAYERS, OUTPUT_DIM, DROPOUT).to(device)\n",
    "model_path = path_to_saves + f'model_{model_id}_{col}.pth'\n",
    "model.load_state_dict(copy.deepcopy(torch.load(model_path)))\n",
    "\n",
    "train_disc_loader = prepare_disc_data(model, train_loader, dataset, X_train_tensor, criterion, \n",
    "                                      attack_fun, attack_params, n_steps=n_steps, device=device, \n",
    "                                      batch_size=batch_size, train_mode=train_mode)\n",
    "\n",
    "test_disc_loader = prepare_disc_data(model, test_loader, dataset, X_test_tensor, criterion, \n",
    "                                     attack_fun_test, attack_params_test, n_steps=n_steps, device=device, \n",
    "                                     batch_size=batch_size, train_mode=train_mode)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
