{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.data import load_Ford_A, transform_data, MyDataset\n",
    "from models.models import LSTM_net, TS2VecClassifier\n",
    "\n",
    "from utils.attacks import ifgsm_procedure\n",
    "from utils.utils import save_experiment, load_disc_model\n",
    "from utils.discrim_training import HideAttackExp\n",
    "from utils.config import get_attack, load_disc_config\n",
    "from utils.attacks import (fgsm_disc_attack, fgsm_attack, fgsm_reg_attack, \n",
    "simba_binary, simba_binary_reg, simba_binary_disc_reg)\n",
    "from utils.data import transform_data, MyDataset\n",
    "\n",
    "from utils.TS2Vec.datautils import load_UCR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_UCR('Strawberry')\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = transform_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_datasets = [\n",
    "        'AllGestureWiimoteX',\n",
    "        'AllGestureWiimoteY',\n",
    "        'AllGestureWiimoteZ',\n",
    "        'BME',\n",
    "        'Chinatown',\n",
    "        'Crop',\n",
    "        'EOGHorizontalSignal',\n",
    "        'EOGVerticalSignal',\n",
    "        'Fungi',\n",
    "        'GestureMidAirD1',\n",
    "        'GestureMidAirD2',\n",
    "        'GestureMidAirD3',\n",
    "        'GesturePebbleZ1',\n",
    "        'GesturePebbleZ2',\n",
    "        'GunPointAgeSpan',\n",
    "        'GunPointMaleVersusFemale',\n",
    "        'GunPointOldVersusYoung',\n",
    "        'HouseTwenty',\n",
    "        'InsectEPGRegularTrain',\n",
    "        'InsectEPGSmallTrain',\n",
    "        'MelbournePedestrian',\n",
    "        'PickupGestureWiimoteZ',\n",
    "        'PigAirwayPressure',\n",
    "        'PigArtPressure',\n",
    "        'PigCVP',\n",
    "        'PLAID',\n",
    "        'PowerCons',\n",
    "        'Rock',\n",
    "        'SemgHandGenderCh2',\n",
    "        'SemgHandMovementCh2',\n",
    "        'SemgHandSubjectCh2',\n",
    "        'ShakeGestureWiimoteZ',\n",
    "        'SmoothSubspace',\n",
    "        'UMD'\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhalangesOutlinesCorrect 1800 858\n",
      "NonInvasiveFetalECGThorax1 1800 1965\n",
      "FordB 3636 810\n",
      "ElectricDevices 8926 7711\n",
      "FordA 3601 1320\n",
      "NonInvasiveFetalECGThorax2 1800 1965\n"
     ]
    }
   ],
   "source": [
    "all_datasets = os.listdir(f'data/TS2Vec/UCR')\n",
    "skip_list = ['Missing_value_and_variable_length_datasets_adjusted', 'UCRArchive_2018.zip', 'Descriptions',\n",
    "                'Multivariate2018_arff.zip', 'EigenWorms', 'Images']\n",
    "\n",
    "for dataset in all_datasets:\n",
    "    if dataset in bad_datasets or dataset in skip_list:\n",
    "        continue\n",
    "    X_train, y_train, X_test, y_test = load_UCR(dataset)\n",
    "    if len(X_train) > 1000:\n",
    "        print(dataset, len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 286), (28, 286), (28,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3601, 500), (1320, 500), (3601,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_Ford_A()\n",
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'checkpoints/Coffee/model_1_Coffee_metrics.pickle'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    results_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results_train['test']['f1'], label='f1')\n",
    "plt.plot(results_train['test']['accuracy'], label='accuracy')\n",
    "plt.plot(results_train['test']['balance'], label='balance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resave ts2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n",
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n",
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n",
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n",
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n"
     ]
    }
   ],
   "source": [
    "#all_weights = sorted(os.listdir('checkpoints/TS2Vec/emb_models/UCR'))\n",
    "\n",
    "glob_dataset_name = 'UCR'\n",
    "dataset_name = 'FordA'\n",
    "adv = ''\n",
    "\n",
    "model = TS2VecClassifier()\n",
    "\n",
    "for model_id in range(5):\n",
    "    \n",
    "    path_emb = f'checkpoints/TS2Vec/emb_models{adv}/{glob_dataset_name}/{dataset_name}_{model_id}.pt'\n",
    "    path_head = f'checkpoints/TS2Vec/class_models{adv}/{glob_dataset_name}/{dataset_name}_{model_id}.pt'\n",
    "    path_save = f'checkpoints/TS2Vec/entire_model/{glob_dataset_name}/{dataset_name}/model_{model_id}_{dataset_name}.pth'\n",
    "\n",
    "    model.load_old(path_emb, path_head)\n",
    "\n",
    "    path = '/'.join(path_save.split('/')[:-1])\n",
    "    print(path)\n",
    "\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "\n",
    "    model.save(path_save)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check ts2vec metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils.TS2Vec.datautils import load_UCR\n",
    "from models.models import  TS2VecClassifier\n",
    "from utils.data import transform_data, MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_grad(model: nn.Module, state: bool = True) -> None:\n",
    "    \"\"\"Set requires_grad of all model parameters to the desired value.\n",
    "\n",
    "    :param model: the model\n",
    "    :param state: desired value for requires_grad\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 286, 1)\n",
      "(28, 286)\n",
      "torch.Size([28, 286]) torch.Size([28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0496, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 0\n",
    "dataset_name = 'Coffee'\n",
    "disc_model_name = 'fgsm_reg_attack_eps=0.2_alpha=0.01_nsteps=4'\n",
    "glob_dataset_name = 'UCR'\n",
    "adv = ''\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_UCR(dataset_name)\n",
    "\n",
    "print(X_test.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = transform_data(X_train, X_test, y_train, y_test, slice_data=False)\n",
    "\n",
    "# X_train = np.where(np.isnan(X_train), 0, X_train)\n",
    "# X_test = np.where(np.isnan(X_test), 0, X_test)\n",
    "\n",
    "# X_train, y_train = torch.from_numpy(X_train).to(torch.float), torch.from_numpy(y_train).to(torch.float)\n",
    "# X_test, y_test = torch.from_numpy(X_test).to(torch.float), torch.from_numpy(y_test).to(torch.float)\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "model = TS2VecClassifier()\n",
    "path_save = f'checkpoints/TS2Vec/entire_model/{glob_dataset_name}/{dataset_name}/model_{model_id}_{dataset_name}.pth'\n",
    "model.load(path_save)\n",
    "model = model.eval()\n",
    "\n",
    "\n",
    "disc_model = TS2VecClassifier(dropout=0.1, n_layers=1, dropout_ts2vec=0.0)\n",
    "path_save = f'results/{dataset_name}/IFGSM/Discriminator_pickle/{disc_model_name}/{model_id}.pt'\n",
    "disc_model.load(path_save)\n",
    "disc_model = disc_model.eval()\n",
    "req_grad(model, state=True)\n",
    "\n",
    "y_pred = disc_model(X_test.unsqueeze(-1))\n",
    "disc_prediction = torch.mean(y_pred.to(float).cpu())\n",
    "disc_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TS2VecClassifier(\n",
       "  (emd_model): AveragedModel(\n",
       "    (module): TSEncoder(\n",
       "      (input_fc): Linear(in_features=1, out_features=64, bias=True)\n",
       "      (feature_extractor): DilatedConvEncoder(\n",
       "        (net): Sequential(\n",
       "          (0): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            )\n",
       "          )\n",
       "          (2): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "            )\n",
       "          )\n",
       "          (3): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "            )\n",
       "          )\n",
       "          (4): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "            )\n",
       "          )\n",
       "          (5): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "            )\n",
       "          )\n",
       "          (6): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "            )\n",
       "          )\n",
       "          (7): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "            )\n",
       "          )\n",
       "          (8): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,))\n",
       "            )\n",
       "          )\n",
       "          (9): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(512,), dilation=(512,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(512,), dilation=(512,))\n",
       "            )\n",
       "          )\n",
       "          (10): ConvBlock(\n",
       "            (conv1): SamePadConv(\n",
       "              (conv): Conv1d(64, 320, kernel_size=(3,), stride=(1,), padding=(1024,), dilation=(1024,))\n",
       "            )\n",
       "            (conv2): SamePadConv(\n",
       "              (conv): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(1024,), dilation=(1024,))\n",
       "            )\n",
       "            (projector): Conv1d(64, 320, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (repr_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): HeadClassifier(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (sigm): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1320, 500, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9295, dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test.unsqueeze(-1))\n",
    "y_pred_real = (y_pred.flatten() > 0.5).to(int).cpu()\n",
    "\n",
    "acc = torch.mean((y_pred_real == y_test).to(float))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1055, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = disc_model(X_test.unsqueeze(-1))\n",
    "disc_prediction = torch.mean(y_pred.to(float).cpu())\n",
    "disc_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8929, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test.unsqueeze(-1))\n",
    "y_pred_real = (y_pred.flatten() > 0.5).to(int).cpu()\n",
    "acc = torch.mean((y_pred_real == y_test).to(float))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_train.unsqueeze(-1))\n",
    "y_pred_real = (y_pred > 0.5).to(int)\n",
    "\n",
    "acc = torch.mean((y_pred_real == y_train).to(float))\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resave disc models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c5013aad8d4c3f95dd92a5f7fa040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 5.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 6.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 7.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 8.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 9.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 5.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 6.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 7.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 8.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 9.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.03_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.03_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.03_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.03_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 5.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 6.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 7.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 8.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 9.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.01_alpha=0.01_nsteps=10 0.pickle\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.01_alpha=0.01_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.01_alpha=0.01_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.01_alpha=0.01_nsteps=10 3.pt\n"
     ]
    }
   ],
   "source": [
    "path = 'results/Ford_A/IFGSM/Discriminator_pickle'\n",
    "folders = sorted(os.listdir(path))\n",
    "folders = [fold for fold in folders if '.pickle' not in fold]\n",
    "\n",
    "\n",
    "for fold in tqdm(folders):\n",
    "    path_loc = path + '/' + fold\n",
    "    pickles = sorted(os.listdir(path_loc))\n",
    "    pickles = [file for file in pickles if 'log' not in file or 'pt' in file]\n",
    "\n",
    "    for pickle_file in pickles:\n",
    "        try:\n",
    "            with open(path_loc + '/' + pickle_file, 'rb') as f:\n",
    "                experiment = pickle.load(f)\n",
    "            \n",
    "            model_weights_name = path_loc + '/' + pickle_file.replace('pickle', 'pt')\n",
    "            torch.save(experiment.disc_model.state_dict(), model_weights_name)\n",
    "\n",
    "            logs_name =  path_loc + '/' + pickle_file.replace('.pickle', '_logs.pickle')\n",
    "            with open(logs_name, 'wb') as f:\n",
    "                pickle.dump(experiment.dict_logging, f)\n",
    "        except:\n",
    "            print('FAIL', path_loc, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.geomspace(0.001, 1.0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
