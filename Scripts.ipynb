{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.data import load_Ford_A, transform_data, MyDataset\n",
    "from models.models import LSTM_net, TS2VecClassifier\n",
    "\n",
    "from utils.attacks import ifgsm_procedure\n",
    "from utils.utils import save_experiment, load_disc_model\n",
    "from utils.discrim_training import HideAttackExp\n",
    "from utils.config import get_attack, load_disc_config\n",
    "from utils.attacks import (fgsm_disc_attack, fgsm_attack, fgsm_reg_attack, \n",
    "simba_binary, simba_binary_reg, simba_binary_disc_reg)\n",
    "from utils.data import transform_data, MyDataset\n",
    "\n",
    "from utils.TS2Vec.datautils import load_UCR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_UCR('Strawberry')\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = transform_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_datasets = [\n",
    "        'AllGestureWiimoteX',\n",
    "        'AllGestureWiimoteY',\n",
    "        'AllGestureWiimoteZ',\n",
    "        'BME',\n",
    "        'Chinatown',\n",
    "        'Crop',\n",
    "        'EOGHorizontalSignal',\n",
    "        'EOGVerticalSignal',\n",
    "        'Fungi',\n",
    "        'GestureMidAirD1',\n",
    "        'GestureMidAirD2',\n",
    "        'GestureMidAirD3',\n",
    "        'GesturePebbleZ1',\n",
    "        'GesturePebbleZ2',\n",
    "        'GunPointAgeSpan',\n",
    "        'GunPointMaleVersusFemale',\n",
    "        'GunPointOldVersusYoung',\n",
    "        'HouseTwenty',\n",
    "        'InsectEPGRegularTrain',\n",
    "        'InsectEPGSmallTrain',\n",
    "        'MelbournePedestrian',\n",
    "        'PickupGestureWiimoteZ',\n",
    "        'PigAirwayPressure',\n",
    "        'PigArtPressure',\n",
    "        'PigCVP',\n",
    "        'PLAID',\n",
    "        'PowerCons',\n",
    "        'Rock',\n",
    "        'SemgHandGenderCh2',\n",
    "        'SemgHandMovementCh2',\n",
    "        'SemgHandSubjectCh2',\n",
    "        'ShakeGestureWiimoteZ',\n",
    "        'SmoothSubspace',\n",
    "        'UMD'\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhalangesOutlinesCorrect 1800 858\n",
      "NonInvasiveFetalECGThorax1 1800 1965\n",
      "FordB 3636 810\n",
      "ElectricDevices 8926 7711\n",
      "FordA 3601 1320\n",
      "NonInvasiveFetalECGThorax2 1800 1965\n"
     ]
    }
   ],
   "source": [
    "all_datasets = os.listdir(f'data/TS2Vec/UCR')\n",
    "skip_list = ['Missing_value_and_variable_length_datasets_adjusted', 'UCRArchive_2018.zip', 'Descriptions',\n",
    "                'Multivariate2018_arff.zip', 'EigenWorms', 'Images']\n",
    "\n",
    "for dataset in all_datasets:\n",
    "    if dataset in bad_datasets or dataset in skip_list:\n",
    "        continue\n",
    "    X_train, y_train, X_test, y_test = load_UCR(dataset)\n",
    "    if len(X_train) > 1000:\n",
    "        print(dataset, len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 286), (28, 286), (28,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3601, 500), (1320, 500), (3601,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_Ford_A()\n",
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'checkpoints/Coffee/model_1_Coffee_metrics.pickle'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    results_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results_train['test']['f1'], label='f1')\n",
    "plt.plot(results_train['test']['accuracy'], label='accuracy')\n",
    "plt.plot(results_train['test']['balance'], label='balance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resave ts2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n",
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n",
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n",
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n",
      "checkpoints/TS2Vec/entire_model/UCR/FordA\n"
     ]
    }
   ],
   "source": [
    "#all_weights = sorted(os.listdir('checkpoints/TS2Vec/emb_models/UCR'))\n",
    "\n",
    "glob_dataset_name = 'UCR'\n",
    "dataset_name = 'FordA'\n",
    "adv = ''\n",
    "\n",
    "model = TS2VecClassifier()\n",
    "\n",
    "for model_id in range(5):\n",
    "    \n",
    "    path_emb = f'checkpoints/TS2Vec/emb_models{adv}/{glob_dataset_name}/{dataset_name}_{model_id}.pt'\n",
    "    path_head = f'checkpoints/TS2Vec/class_models{adv}/{glob_dataset_name}/{dataset_name}_{model_id}.pt'\n",
    "    path_save = f'checkpoints/TS2Vec/entire_model/{glob_dataset_name}/{dataset_name}/model_{model_id}_{dataset_name}.pth'\n",
    "\n",
    "    model.load_old(path_emb, path_head)\n",
    "\n",
    "    path = '/'.join(path_save.split('/')[:-1])\n",
    "    print(path)\n",
    "\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "\n",
    "    model.save(path_save)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check ts2vec metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.TS2Vec.datautils import load_UCR\n",
    "from models.models import  TS2VecClassifier\n",
    "from utils.data import transform_data, MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1320, 500, 1)\n",
      "(1320, 500)\n",
      "torch.Size([1320, 500]) torch.Size([1320])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 2; 15.78 GiB total capacity; 1.18 MiB already allocated; 3.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6717654a3f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdisc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTS2VecClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mpath_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'results/{dataset_name}/IFGSM/Discriminator_pickle/{disc_model_name}/{model_id}.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdisc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mdisc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AA/Package/models/models.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         loaded_storages[key] = torch.storage.TypedStorage(\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m             dtype=dtype)\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mps_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             untyped_storage = torch.UntypedStorage(\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 2; 15.78 GiB total capacity; 1.18 MiB already allocated; 3.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model_id = 1\n",
    "dataset_name = 'FordA'\n",
    "disc_model_name = 'fgsm_reg_attack_new_eps=0.13_alpha=0.0001_nsteps=10'\n",
    "glob_dataset_name = 'UCR'\n",
    "adv = ''\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_UCR(dataset_name)\n",
    "\n",
    "print(X_test.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = transform_data(X_train, X_test, y_train, y_test, slice_data=False)\n",
    "\n",
    "# X_train = np.where(np.isnan(X_train), 0, X_train)\n",
    "# X_test = np.where(np.isnan(X_test), 0, X_test)\n",
    "\n",
    "# X_train, y_train = torch.from_numpy(X_train).to(torch.float), torch.from_numpy(y_train).to(torch.float)\n",
    "# X_test, y_test = torch.from_numpy(X_test).to(torch.float), torch.from_numpy(y_test).to(torch.float)\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "model = TS2VecClassifier()\n",
    "path_save = f'checkpoints/TS2Vec/entire_model/{glob_dataset_name}/{dataset_name}/model_{model_id}_{dataset_name}.pth'\n",
    "model.load(path_save)\n",
    "model = model.eval()\n",
    "\n",
    "\n",
    "disc_model = TS2VecClassifier(dropout=0.0, n_layers=2)\n",
    "path_save = f'results/{dataset_name}/IFGSM/Discriminator_pickle/{disc_model_name}/{model_id}.pt'\n",
    "disc_model.load(path_save)\n",
    "disc_model = disc_model.eval()\n",
    "\n",
    "y_pred = disc_model(X_test.unsqueeze(-1))\n",
    "disc_prediction = torch.mean(y_pred.to(float).cpu())\n",
    "disc_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9295, dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test.unsqueeze(-1))\n",
    "y_pred_real = (y_pred.flatten() > 0.5).to(int).cpu()\n",
    "\n",
    "acc = torch.mean((y_pred_real == y_test).to(float))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1055, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = disc_model(X_test.unsqueeze(-1))\n",
    "disc_prediction = torch.mean(y_pred.to(float).cpu())\n",
    "disc_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8929, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test.unsqueeze(-1))\n",
    "y_pred_real = (y_pred.flatten() > 0.5).to(int).cpu()\n",
    "acc = torch.mean((y_pred_real == y_test).to(float))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_train.unsqueeze(-1))\n",
    "y_pred_real = (y_pred > 0.5).to(int)\n",
    "\n",
    "acc = torch.mean((y_pred_real == y_train).to(float))\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resave disc models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c5013aad8d4c3f95dd92a5f7fa040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 5.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 6.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 7.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 8.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.005_nsteps=10 9.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 5.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 6.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 7.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 8.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.01_nsteps=10 9.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.03_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.03_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.03_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.03_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.05_nsteps=1 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_attack_eps=0.3_nsteps=1 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 5.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 6.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 7.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 8.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.01_nsteps=10 9.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 0.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 3.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.005_alpha=0.1_nsteps=10 4.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.01_alpha=0.01_nsteps=10 0.pickle\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.01_alpha=0.01_nsteps=10 1.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.01_alpha=0.01_nsteps=10 2.pt\n",
      "FAIL results/Ford_A/IFGSM/Discriminator_pickle/fgsm_reg_attack_eps=0.01_alpha=0.01_nsteps=10 3.pt\n"
     ]
    }
   ],
   "source": [
    "path = 'results/Ford_A/IFGSM/Discriminator_pickle'\n",
    "folders = sorted(os.listdir(path))\n",
    "folders = [fold for fold in folders if '.pickle' not in fold]\n",
    "\n",
    "\n",
    "for fold in tqdm(folders):\n",
    "    path_loc = path + '/' + fold\n",
    "    pickles = sorted(os.listdir(path_loc))\n",
    "    pickles = [file for file in pickles if 'log' not in file or 'pt' in file]\n",
    "\n",
    "    for pickle_file in pickles:\n",
    "        try:\n",
    "            with open(path_loc + '/' + pickle_file, 'rb') as f:\n",
    "                experiment = pickle.load(f)\n",
    "            \n",
    "            model_weights_name = path_loc + '/' + pickle_file.replace('pickle', 'pt')\n",
    "            torch.save(experiment.disc_model.state_dict(), model_weights_name)\n",
    "\n",
    "            logs_name =  path_loc + '/' + pickle_file.replace('.pickle', '_logs.pickle')\n",
    "            with open(logs_name, 'wb') as f:\n",
    "                pickle.dump(experiment.dict_logging, f)\n",
    "        except:\n",
    "            print('FAIL', path_loc, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.geomspace(0.001, 1.0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
